{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " DAE pytorch one hot_1 test",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4TMJcPvmdrG",
        "colab_type": "text"
      },
      "source": [
        "#Collaborative Filtering using deep learning\n",
        "Vineet Kothari\n",
        "50291159\n",
        "vineetsu@buffalo.edu\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC9MsR6_mK0m",
        "colab_type": "text"
      },
      "source": [
        "##Ultimate cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J88tQp2L-ktx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "from torch import nn, optim\n",
        "from torch.autograd.variable import Variable\n",
        "from torchvision import transforms, datasets\n",
        "import os\n",
        "from PIL import Image\n",
        "import glob\n",
        "import PIL\n",
        "from PIL import ImageFont\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from bokeh.io import curdoc, show, output_notebook\n",
        "from bokeh.layouts import column\n",
        "from bokeh.models import ColumnDataSource\n",
        "from bokeh.plotting import figure\n",
        "from functools import partial\n",
        "from threading import Thread\n",
        "from tornado import gen\n",
        "import time\n",
        "import pickle\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm\n",
        "from functools import reduce\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#parameters\n",
        "batch_size=100\n",
        "train_split=0.8\n",
        "num_epochs=5\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeKL-SIvvVf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_1HnrK2O5eA",
        "colab_type": "code",
        "outputId": "c3a8ec2a-b0f5-49dd-d646-b8b73853b0ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWf-SqtJPIrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#paths\n",
        "root_dir=\"/content/drive/My Drive/Projects/Collaborative filtering/\"\n",
        "fcodes_dataset_path=\"/content/drive/My Drive/Projects/Collaborative filtering/Datasets/fcodesbucket edited - fcodesbucket.csv\"\n",
        "version=\"dae-3\"\n",
        "ckpt_dir=\"/content/drive/My Drive/Projects/Collaborative filtering/Implementations/dae-3/checkpoints/\"\n",
        "model_dir=\"/content/drive/My Drive/Projects/Collaborative filtering/Implementations/dae-3/checkpoints/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SFyeB66QHbV",
        "colab_type": "code",
        "outputId": "bc80b4ca-3a44-4291-ee79-05982b6304b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text=open(fcodes_dataset_path).read()\n",
        "print(\"Text is {} characters long\".format(len(text)))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text is 381175 characters long\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-LnL7wGj9eE",
        "colab_type": "code",
        "outputId": "156cc1c0-fea4-4644-be9c-2df6f7029c09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "histories=[h for h in text.split('\\n')]\n",
        "print(\"Data has {} patient histories\".format(len(histories)))\n",
        "n_patients=len(histories)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data has 6237 patient histories\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx4nx_oZkfiW",
        "colab_type": "code",
        "outputId": "4f7c8ac4-ba5b-46e5-d629-c00adbb5b6e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_patients=len(histories)\n",
        "\n",
        "real_data=[]\n",
        "for history in histories:\n",
        "  real_data.append([symptom for symptom in history.split(',')])\n",
        "for history in real_data:\n",
        "  while \"\" in history:\n",
        "    history.remove(\"\")\n",
        "  history.append(\"End\")\n",
        "\n",
        "real_data[0]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['H269', 'D259', 'F067', 'End']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7RGQ2_Fmis_",
        "colab_type": "text"
      },
      "source": [
        "Sorting the symptoms, except the last 'end'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiB3IKvXmegm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i,_ in enumerate(real_data):\n",
        "  real_data[i]=sorted(real_data[i][:-1])+[real_data[i][-1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtwtPnTvsbs0",
        "colab_type": "text"
      },
      "source": [
        "Splitting each symptom in to 3 levels\n",
        "e.g. A423 as A, 42, 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTNKON-_3Cqv",
        "colab_type": "text"
      },
      "source": [
        "Splitting one history into multiple sub histories\n",
        "H, 20, 4, G,12,6 into\n",
        "[H],[H,20],[H,20,4],[H,20,4,G]\n",
        "\n",
        "Min length has to be 4.\n",
        "i.e. One whole symptom has to be there (Not split, whole with all 3 levels) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HCoNkH0qwS9",
        "colab_type": "code",
        "outputId": "d1d41b06-9879-4b70-9e24-df622f8887f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data=[]\n",
        "for history in real_data:\n",
        "  hist=[]\n",
        "  for s in history:\n",
        "    if s!=\"End\":\n",
        "      try:\n",
        "        hist.extend([s[0],s[1:3],s[3]])\n",
        "      except:\n",
        "        hist.extend([s[0],s[1:3],'0'])\n",
        "    else:\n",
        "      hist.append(s)\n",
        "  data.append(hist)\n",
        "data[0]\n",
        "\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['D', '25', '9', 'F', '06', '7', 'H', '26', '9', 'End']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JOR_a-Ugrji",
        "colab_type": "code",
        "outputId": "297be68b-0f3b-4443-be6c-3ffc49563517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data[0]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['D', '25', '9', 'F', '06', '7', 'H', '26', '9', 'End']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT-x2NT5xb9E",
        "colab_type": "text"
      },
      "source": [
        "Combining all histories to one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L5Ox7NTxMHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=[]\n",
        "for history in data:\n",
        "  text.extend(history)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSfwTddbxsAW",
        "colab_type": "text"
      },
      "source": [
        "Each characted mapped as a no."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kpxehY7xbUL",
        "colab_type": "code",
        "outputId": "5e59f3ea-dea4-4d10-9660-da75073a90f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "vocab=sorted(set(text))\n",
        "print(\"There are {} unique characters\".format(len(vocab)))\n",
        "char2int={c:i for i,c in enumerate(vocab)}\n",
        "int2char=np.array(vocab)\n",
        "print(\"Vector:\\n\")\n",
        "for char,_ in zip(char2int,range(8)):\n",
        "  print(' {:4s}: {:3d},'.format(repr(char), char2int[char]))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 132 unique characters\n",
            "Vector:\n",
            "\n",
            " '0' :   0,\n",
            " '00':   1,\n",
            " '01':   2,\n",
            " '02':   3,\n",
            " '03':   4,\n",
            " '04':   5,\n",
            " '05':   6,\n",
            " '06':   7,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd0bYFuZoaQ8",
        "colab_type": "code",
        "outputId": "64eed242-b708-4252-a87c-a1adb8081d4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "char2int['End']"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FjJL1enZjie",
        "colab_type": "text"
      },
      "source": [
        "##Data analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLHhz4B4Z03w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flatten2D(grid):\n",
        "  a=[]\n",
        "  for x in grid:\n",
        "    a.extend(x)\n",
        "  return a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf2qKJbW0qPf",
        "colab_type": "text"
      },
      "source": [
        "Mapping each of the level codes in histories to nos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amANcWru0Jzu",
        "colab_type": "code",
        "outputId": "64a1d2fe-85cf-4cff-ca8d-cf0371b86b1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "int_data=[]\n",
        "for history in data:\n",
        "  int_data.append(np.array([char2int[level_code] for level_code in history],dtype=np.int32))\n",
        "int_data=np.array(int_data)\n",
        "print ('{}\\n mapped to integers:\\n {}'.format(repr(data[0]), int_data[0]))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['D', '25', '9', 'F', '06', '7', 'H', '26', '9', 'End']\n",
            " mapped to integers:\n",
            " [113  28  99 116   7  77 118  29  99 115]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MC4ZvBBxi-d",
        "colab_type": "text"
      },
      "source": [
        "Creating training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhn6W6DN9j3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_histories=len(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAg_YNaSpXVC",
        "colab_type": "text"
      },
      "source": [
        "BLinding it with no 420"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3YC_YKV2ec6",
        "colab_type": "code",
        "outputId": "6ff857ca-eedf-4aed-a966-f1c93f337f62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Find the max length of history\n",
        "max_history_len=0\n",
        "for history in int_data:\n",
        "  max_history_len=max(len(history),max_history_len)\n",
        "print(\"Longest history of a patient: \",max_history_len)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longest history of a patient:  94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s5fnKdS9YHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Find the max length of history\n",
        "# max_history_len=0\n",
        "# for history in encode_data:\n",
        "#   max_history_len=max(len(history),max_history_len)\n",
        "# print(\"Longest history of a patient: \",max_history_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAzugJNWx5Nh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def random_blinding(history):\n",
        "#   n=len(history)\n",
        "#   history=list(map(lambda x:x/132,history))\n",
        "#   y_history=history.copy()\n",
        "#   req_len=95-n\n",
        "#   res=[]\n",
        "#   for it in range(2*n):\n",
        "#     temp=history.copy()\n",
        "#     blind_indices = random.sample(range(0, n), round(n*0.3)) \n",
        "#     for i in blind_indices:\n",
        "#       temp[i]=1   \n",
        "#     #Padding shoudl be done here. since, \n",
        "    \n",
        "#     temp=np.append(temp,[(char2int['End'])/132]*req_len)\n",
        "#     y_history=np.append(history.copy(),[(char2int['End'])/132]*req_len)\n",
        "    \n",
        "#     res.append([temp,y_history])\n",
        "#   return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_EkW7D6pcYb",
        "colab_type": "text"
      },
      "source": [
        "This is complete blinding. But needs to be optimized as the RAM limits the operation. Cool no problem as of now!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDzyIkWctxIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"Blinding the integer codes of diseases with no. 420\")\n",
        "# print(\"BLINDING PERCENT 30%.\\n \")\n",
        "\n",
        "# aug_int_data=[]\n",
        "# for history in int_data:\n",
        "#   aug_int_data.extend(random_blinding(history))\n",
        "# n_aug_histories=len(aug_int_data)\n",
        "# #aug_int_data=np.array(aug_int_data)\n",
        "\n",
        "# print(\"Length of complete data points:\",len(aug_int_data)) # blinded data\n",
        "# print(\"Example of a blinded data pointL: \",aug_int_data[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMoGZoQu3rU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_single_vector(vector):\n",
        "  res_vector=[]\n",
        "  for value in vector:\n",
        "    encoded_value=[0]*132\n",
        "    if value!=132:\n",
        "      encoded_value[value]=1\n",
        "    res_vector.append(encoded_value)\n",
        "  return res_vector\n",
        "\n",
        "def one_hot_encode(int_data):\n",
        "  res=[]\n",
        "  padded_input=[0]*132\n",
        "  padded_input[char2int['End']]=1\n",
        "  for history in int_data:\n",
        "    n=len(history)\n",
        "    #y_history=history.copy()\n",
        "    req_len=95-n\n",
        "    res.append(encode_single_vector(history)+[padded_input]*req_len)\n",
        "  return res\n",
        "\n",
        "def random_blinding(history):\n",
        "  n=len(history)\n",
        "  #y_history=history.copy()\n",
        "  req_len=95-n\n",
        "  res=[]\n",
        "  for it in range(2*n):\n",
        "    temp=history.copy()\n",
        "    blind_indices = random.sample(range(0, n), round(n*0.3)) \n",
        "    for i in blind_indices:\n",
        "      temp[i]=[0]*132   \n",
        "    #Padding shoudl be done here. since, \n",
        "    padded_input=[0]*132\n",
        "    padded_input[char2int['End']]=1\n",
        "    #temp=np.append(temp,[padded_input]*req_len)\n",
        "    #y_history=np.append(history.copy(),[padded_input]*req_len)\n",
        "    \n",
        "    res.append([np.append(temp,[padded_input]*req_len),np.append(history.copy(),[padded_input]*req_len)])\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YdF7awl8vms",
        "colab_type": "code",
        "outputId": "b01534f8-4204-4c35-d42a-7a0f0c7be33c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encode_data=one_hot_encode(int_data)\n",
        "print(\"Dimensions of encoded data are: ({},{},{})\".format(len(encode_data),len(encode_data[0]),len(encode_data[0][0])))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimensions of encoded data are: (6237,95,132)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6geTVpnB9Axs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"Blinding the integer codes of diseases with zeros\")\n",
        "# print(\"BLINDING PERCENT 30%.\\n \")\n",
        "\n",
        "# aug_encode_data=[]\n",
        "# for history in encode_data:\n",
        "#   aug_encode_data.extend(random_blinding(history))\n",
        "# n_aug_histories=len(aug_encode_data)\n",
        "# #aug_int_data=np.array(aug_int_data)\n",
        "\n",
        "# print(\"Length of complete data points:\",len(aug_encode_data)) # blinded data\n",
        "# print(\"Example of a blinded data pointL: \",aug_encode_data[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgBCUsppbPO2",
        "colab_type": "text"
      },
      "source": [
        "TODO: https://discuss.pytorch.org/t/where-is-the-noise-layer-in-pytorch/2887/6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meR_wLQBjfru",
        "colab_type": "text"
      },
      "source": [
        "##From Tensorflow doc - Creating dataset\n",
        "https://www.tensorflow.org/tutorials/load_data/text\n",
        "\n",
        "Pytorch GRU with attention maps\n",
        "https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#sphx-glr-intermediate-seq2seq-translation-tutorial-py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGY8TLh9qeHm",
        "colab_type": "text"
      },
      "source": [
        "##Pytorch code starts here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5z4AE7_qjBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class listDataset(torch.utils.data.Dataset):\n",
        "#   def __init__(self,aug_int_data):\n",
        "#     self.aug_int_data=aug_int_data\n",
        "     \n",
        "#     self.data_transform=transforms.Compose([\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Normalize([0.485],[0.229]) # need to normalize . How to do this will find out!.\n",
        "#     ]) # oh my god! I also need to pad the input! Cool. # shoudl I do it before? would be easy.\n",
        "    \n",
        "#   def __getitem__(self,index):\n",
        "    \n",
        "#     blind_input=(self.aug_int_data[index][0]) # Rememeber each data point is a numpy array. Indexing might be different\n",
        "#     real_input=(self.aug_int_data[index][1]) #need to put the data variable. \n",
        "#     return blind_input,real_input\n",
        "  \n",
        "#   def __len__(self):\n",
        "#     return len(self.aug_int_data)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ_xryc6Ku6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def single_random_blind(history):\n",
        "  n=len(history)\n",
        "  blind_indices = random.sample(range(0, n), round(n*0.3)) \n",
        "  for i in blind_indices:\n",
        "    history[i]=[0]*132\n",
        "  return history   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfFmyTSbKRw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class listDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,encode_data):\n",
        "    self.encode_data=encode_data\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    temp1,temp2=self.encode_data[index].copy(),self.encode_data[index].copy()\n",
        "    blind_input=flatten2D(single_random_blind(temp1)) \n",
        "    real_input=flatten2D(temp2) \n",
        "    return torch.Tensor(blind_input),torch.Tensor(real_input)\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.encode_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7iRYdPmK_kS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=listDataset(encode_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYa22W8v4P4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset=listDataset(aug_int_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1ScUSjyLCU5",
        "colab_type": "code",
        "outputId": "bd0508b4-3909-4cf9-9277-a0e56c95aab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#example of an iteration of dataloader\n",
        "len(iter(torch.utils.data.DataLoader(dataset)).next()[1])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxvqERkfMcso",
        "colab_type": "text"
      },
      "source": [
        "Splitting into training and validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS3f9DyuMb8i",
        "colab_type": "code",
        "outputId": "77ec683d-714a-474e-e3ae-e3f29948b512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"Splitting the dataloader into training and validation..\\n\")\n",
        "train_size=int(train_split*len(dataset))\n",
        "val_size=len(dataset)-train_size\n",
        "batch_size=64\n",
        "train_dataset, val_dataset=torch.utils.data.random_split(dataset,[train_size,val_size])\n",
        "train_dataloader=torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                             batch_size=batch_size,\n",
        "                                             shuffle=True)\n",
        "num_batches=len(train_dataloader)\n",
        "val_dataloader=torch.utils.data.DataLoader(dataset=val_dataset,\n",
        "                                             batch_size=batch_size,\n",
        "                                             shuffle=True)\n",
        "print(\"Length of train dataset :{}, of val dataset:{}\".format(\n",
        "    len(train_dataset),len(val_dataset)\n",
        "))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Splitting the dataloader into training and validation..\n",
            "\n",
            "Length of train dataset :4989, of val dataset:1248\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A32J1BzLfZbv",
        "colab_type": "code",
        "outputId": "a56283f5-67fe-4b91-a691-359ae988b634",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "iter(train_dataloader).next()[0].shape\n",
        "#this means there are 2 lists, blind and real of 12540 tensors. and each tensor is of batch_size. BOOM\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 12540])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj4hxz4hhpSc",
        "colab_type": "code",
        "outputId": "a12d99ab-0cd3-4c80-dc68-1e48f375b4a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_dataset[1][1])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12540"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTP9FKAZNWVU",
        "colab_type": "text"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ26mkA3NV5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Autoencoder(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,latent_rep_size):\n",
        "    super(Autoencoder,self).__init__()\n",
        "    self.fc1= nn.Linear(input_size,hidden_size)\n",
        "    self.relu1=nn.ReLU()\n",
        "    self.fc2=nn.Linear(hidden_size,latent_rep_size)\n",
        "    self.relu2=nn.ReLU()\n",
        "    self.fc3=nn.Linear(latent_rep_size,hidden_size)\n",
        "    self.relu3=nn.ReLU()\n",
        "    self.fc4= nn.Linear(hidden_size,input_size)\n",
        "    self.t=nn.Sigmoid()\n",
        "\n",
        "  def weight_init(self, mean=0.0, std=0.02):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m]) \n",
        "\n",
        "  def forward(self,x):\n",
        "    out=self.fc1(x)\n",
        "    out=self.relu1(out)\n",
        "    out=self.fc2(out)\n",
        "    out=self.relu2(out)\n",
        "    out=self.fc3(out)\n",
        "    out=self.relu3(out)\n",
        "    out=self.fc4(out)\n",
        "    return self.t(out)\n",
        "\n",
        "\n",
        "def normal_init(m, mean=0.0, std=0.02):\n",
        "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "        m.weight.data.normal_(mean, std)\n",
        "        m.bias.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcV2QltYBdnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#parameters\n",
        "lr=0.002\n",
        "beta1=0.5\n",
        "beta2=0.999\n",
        "L1_lambda=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ogXHUq6OEcP",
        "colab_type": "code",
        "outputId": "7474f0f1-bcbc-4b58-db1e-54d5fcf0088c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#device=\"cpu\"\n",
        "print(\"Training on device: \", device)\n",
        "input_size=12540\n",
        "hidden_size=300\n",
        "latent_rep_size=128\n",
        "model=Autoencoder(input_size,hidden_size, latent_rep_size).to(device)\n",
        "print(model)\n",
        "\n",
        "model.load_state_dict(torch.load(model_dir+'model.ckpt'))\n",
        "model.eval()\n",
        "#Loss and optimizer\n",
        "criterion=nn.MSELoss().to(device)\n",
        "#optimizer=torch.optim.Adam(model.parameters(),lr=lr,betas=(beta1,beta2))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on device:  cuda:0\n",
            "Autoencoder(\n",
            "  (fc1): Linear(in_features=12540, out_features=300, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (fc2): Linear(in_features=300, out_features=128, bias=True)\n",
            "  (relu2): ReLU()\n",
            "  (fc3): Linear(in_features=128, out_features=300, bias=True)\n",
            "  (relu3): ReLU()\n",
            "  (fc4): Linear(in_features=300, out_features=12540, bias=True)\n",
            "  (t): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8XivMm8fsNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def single_bittensor_acc(tensor1, tensor2):\n",
        "  tensor1,tensor2=tensor1.detach().round().int(),tensor2.detach().round().int()\n",
        "  return sum(tensor1^tensor2)\n",
        "\n",
        "def bittensor_acc(tensor1,tensor2):\n",
        "  sum_acc,n=0,len(tensor1)\n",
        "  for t1,t2 in zip(tensor1,tensor2):\n",
        "    sum_acc+=single_bittensor_acc(t1,t2)\n",
        "  return sum_acc/n\n",
        "\n",
        "def  decode_onehot(vector):\n",
        "  if 1 in vector:\n",
        "    return list(vector).index(1)\n",
        "  else:\n",
        "    return -1\n",
        "\n",
        "def decode_disease(vector):\n",
        "  history=list(vector.detach().round().int()).copy()\n",
        "  res=[]\n",
        "  unknown_count=0\n",
        "  for i in range(0,12540,132):\n",
        "    temp=history[i:i+132].copy()\n",
        "    index=decode_onehot(list(temp))\n",
        "    if index!=-1 and index!=115:\n",
        "      res.append(int2char[index])\n",
        "    elif index==115:\n",
        "      res.append(int2char[index])\n",
        "      break\n",
        "    else:\n",
        "      unknown_count+=1\n",
        "      res.append('*')\n",
        "  return unknown_count,res\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlZX_oIPX-W4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# num_epochs=100\n",
        "# total_step=len(train_dataloader)\n",
        "# #model.train()\n",
        "# for epoch in range(num_epochs):\n",
        "#   for i,((blind_vector,real_vector),(bv_val,rv_val)) in enumerate(zip(train_dataloader,val_dataloader)):\n",
        "#     blind_vector=blind_vector.to(device).float()\n",
        "#     real_vector=real_vector.to(device).float() \n",
        "#     bv_val=bv_val.to(device).float()\n",
        "#     rv_val=rv_val.to(device).float() \n",
        "\n",
        "#     outputs=model(blind_vector)\n",
        "#     outputs_val=model(bv_val)\n",
        "#     loss=criterion(outputs,real_vector)\n",
        "#     loss_val=criterion(outputs_val,rv_val)\n",
        "    \n",
        "#     optimizer.zero_grad()\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "    \n",
        "#     if(i+1)%10==0:\n",
        "#       print('Epoch [{}/{}], Step[{}/{}],Training:: Loss:{:.4f},Accuracy:{}         Validation Loss:{:.4f}, Accuracy:{}'\n",
        "#            .format(epoch+1,num_epochs,i+1,total_step,loss.item(),bittensor_acc(outputs,real_vector),loss_val.item(),bittensor_acc(outputs_val,rv_val)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtQWr7ZJE7L3",
        "colab_type": "code",
        "outputId": "ae140ace-942d-4ed2-b356-e2d3836f4623",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "  blind_vector, real_vector=iter(val_dataloader).next()\n",
        "  blind_vector=blind_vector.to(device).float()\n",
        "  real_vector=real_vector.to(device).float()\n",
        "  index=8\n",
        "  outputs=model(blind_vector)\n",
        "  loss=criterion(outputs,real_vector)\n",
        "  print(\"Predicted:\",decode_disease(model(blind_vector)[index]))\n",
        "  print(\"Blinded Input:\",decode_disease(blind_vector[index]))\n",
        "  print(\"Groundtruth:\",decode_disease(real_vector[index]))\n",
        "  print(\"Loss:{:.4f}, Avg. no of bits misclassified: {}, Recall :{:.4f}, Precision :{:.4f}, F1 :{:.4f}\"\n",
        "        .format(loss.item(),bittensor_acc(outputs,real_vector),1.0,1.0,1.0 )\n",
        "  )"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, ['F', '32', '*', '*', '22', '*', 'K', '63', '5', 'K', '80', '2', 'N', '80', '*', 'R', '*', '0', 'End'])\n",
            "(7, ['*', '32', '*', '*', '22', '7', 'K', '63', '*', 'K', '80', '2', 'N', '84', '*', 'R', '51', '*', '*', 'End'])\n",
            "(0, ['F', '32', '9', 'K', '22', '7', 'K', '63', '5', 'K', '80', '2', 'N', '84', '1', 'R', '51', '0', 'End'])\n",
            "Loss:0.0006, Avg. no of bits misclassified: 8, Recall :1.0000, Precision :1.0000, F1 :1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ELyFTErDgs1",
        "colab_type": "text"
      },
      "source": [
        "Hierarchial model\n",
        "\n",
        "RACT Collaborative filtering\n",
        "\n",
        "Journal search VMC,Sciom data mining \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gua6_zXeSgt3",
        "colab_type": "code",
        "outputId": "94640806-ad10-4d45-a0c4-6b398906138b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "precision_recall_fscore_support(flatten2D(list(outputs.cpu().round())),flatten2D(list(real_vector.cpu().round())))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.99989202, 0.92828947]),\n",
              " array([0.99945283, 0.98499127]),\n",
              " array([0.99967238, 0.95580017]),\n",
              " array([796830,   5730]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4zmDq26UEX8",
        "colab_type": "code",
        "outputId": "c701f779-331b-4b2e-986d-7c1d096b8bb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "confusion_matrix(flatten2D(list(outputs.cpu().round())),flatten2D(list(real_vector.cpu().round())))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[796394,    436],\n",
              "       [    86,   5644]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    }
  ]
}