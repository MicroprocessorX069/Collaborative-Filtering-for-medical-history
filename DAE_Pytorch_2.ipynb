{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DAE Pytorch 2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MicroprocessorX069/Collaborative-Filtering-for-medical-history/blob/master/DAE_Pytorch_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXlc4A-xMObg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J88tQp2L-ktx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "from torch import nn, optim\n",
        "from torch.autograd.variable import Variable\n",
        "from torchvision import transforms, datasets\n",
        "import os\n",
        "from PIL import Image\n",
        "import glob\n",
        "import PIL\n",
        "from PIL import ImageFont\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from bokeh.io import curdoc, show, output_notebook\n",
        "from bokeh.layouts import column\n",
        "from bokeh.models import ColumnDataSource\n",
        "from bokeh.plotting import figure\n",
        "from functools import partial\n",
        "from threading import Thread\n",
        "from tornado import gen\n",
        "import time\n",
        "import pickle\n",
        "from torchsummary import summary\n",
        "\n",
        "#parameters\n",
        "batch_size=100\n",
        "train_split=0.8\n",
        "num_epochs=5\n",
        "\n",
        "#input\n",
        "data_dir=\"data\"\n",
        "inp_width=300\n",
        "inp_height=256\n",
        "inp_channels=3\n",
        "\n",
        "#generator\n",
        "ngf=2\n",
        "ndf=2\n",
        "\n",
        "#discriminator\n",
        "ndf=2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdh__AoSYHCe",
        "colab_type": "text"
      },
      "source": [
        "#To copy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dflUNFEBKaBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "# !pip install tensorflow-gpu==2.0\n",
        "# import tensorflow as tf\n",
        "# import numpy as np\n",
        "# import os\n",
        "# import datetime\n",
        "# from tensorflow.python.client import device_lib\n",
        "# print(device_lib.list_local_devices())\n",
        "\n",
        "# print(\"Tensorflow version: \",tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9h_6ZsXvwv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorflow --upgrade --force-reinstall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeKL-SIvvVf6",
        "colab_type": "code",
        "outputId": "344835a9-8634-47b5-ae1c-25d78e3a1494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvHkHgh5QtYA",
        "colab_type": "text"
      },
      "source": [
        "http://biobank.ctsu.ox.ac.uk/crystal/field.cgi?id=41202"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_1HnrK2O5eA",
        "colab_type": "code",
        "outputId": "63276310-405a-4a40-8cb3-ace3a42359f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWf-SqtJPIrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#paths\n",
        "root_dir=\"/content/drive/My Drive/Projects/Collaborative filtering/\"\n",
        "fcodes_dataset_path=\"/content/drive/My Drive/Projects/Collaborative filtering/Datasets/fcodesbucket edited - fcodesbucket.csv\"\n",
        "version=\"dae-2\"\n",
        "ckpt_dir=\"/content/drive/My Drive/Projects/Collaborative filtering/Implementations/lstm-2/checkpoints/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SFyeB66QHbV",
        "colab_type": "code",
        "outputId": "c912d1ba-c196-42e4-adb8-aa7419f06d5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text=open(fcodes_dataset_path).read()\n",
        "print(\"Text is {} characters long\".format(len(text)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text is 381175 characters long\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5ak2el8j5q8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-LnL7wGj9eE",
        "colab_type": "code",
        "outputId": "2654ad61-de5b-4d94-9ed5-0828392b0956",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "histories=[h for h in text.split('\\n')]\n",
        "print(\"Data has {} patient histories\".format(len(histories)))\n",
        "n_patients=len(histories)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data has 6237 patient histories\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx4nx_oZkfiW",
        "colab_type": "code",
        "outputId": "e4494ea2-c1d2-448a-f003-5821aadbe266",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_patients=len(histories)\n",
        "\n",
        "real_data=[]\n",
        "for history in histories:\n",
        "  real_data.append([symptom for symptom in history.split(',')])\n",
        "for history in real_data:\n",
        "  while \"\" in history:\n",
        "    history.remove(\"\")\n",
        "  history.append(\"End\")\n",
        "\n",
        "real_data[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['H269', 'D259', 'F067', 'End']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7RGQ2_Fmis_",
        "colab_type": "text"
      },
      "source": [
        "Sorting the symptoms, except the last 'end'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiB3IKvXmegm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i,_ in enumerate(real_data):\n",
        "  real_data[i]=sorted(real_data[i][:-1])+[real_data[i][-1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtwtPnTvsbs0",
        "colab_type": "text"
      },
      "source": [
        "Splitting each symptom in to 3 levels\n",
        "e.g. A423 as A, 42, 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTNKON-_3Cqv",
        "colab_type": "text"
      },
      "source": [
        "Splitting one history into multiple sub histories\n",
        "H, 20, 4, G,12,6 into\n",
        "[H],[H,20],[H,20,4],[H,20,4,G]\n",
        "\n",
        "Min length has to be 4.\n",
        "i.e. One whole symptom has to be there (Not split, whole with all 3 levels) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HCoNkH0qwS9",
        "colab_type": "code",
        "outputId": "e5b61405-f632-4b0f-fccc-3ad1d3fb0e09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data=[]\n",
        "for history in real_data:\n",
        "  hist=[]\n",
        "  for s in history:\n",
        "    if s!=\"End\":\n",
        "      try:\n",
        "        hist.extend([s[0],s[1:3],s[3]])\n",
        "      except:\n",
        "        hist.extend([s[0],s[1:3],'0'])\n",
        "    else:\n",
        "      hist.append(s)\n",
        "  data.append(hist)\n",
        "data[0]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['D', '25', '9', 'F', '06', '7', 'H', '26', '9', 'End']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JOR_a-Ugrji",
        "colab_type": "code",
        "outputId": "40c82c17-da1f-4d7a-e8fd-a7c5f28eacd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['H', '26', '9', 'D', '25', '9', 'F', '06', '7', 'End']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT-x2NT5xb9E",
        "colab_type": "text"
      },
      "source": [
        "Combining all histories to one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L5Ox7NTxMHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=[]\n",
        "for history in data:\n",
        "  text.extend(history)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSfwTddbxsAW",
        "colab_type": "text"
      },
      "source": [
        "Each characted mapped as a no."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kpxehY7xbUL",
        "colab_type": "code",
        "outputId": "acb2c958-9aa0-45c8-af50-b8573d2734ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "vocab=sorted(set(text))\n",
        "print(\"There are {} unique characters\".format(len(vocab)))\n",
        "char2int={c:i for i,c in enumerate(vocab)}\n",
        "int2char=np.array(vocab)\n",
        "print(\"Vector:\\n\")\n",
        "for char,_ in zip(char2int,range(8)):\n",
        "  print(' {:4s}: {:3d},'.format(repr(char), char2int[char]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 132 unique characters\n",
            "Vector:\n",
            "\n",
            " '0' :   0,\n",
            " '00':   1,\n",
            " '01':   2,\n",
            " '02':   3,\n",
            " '03':   4,\n",
            " '04':   5,\n",
            " '05':   6,\n",
            " '06':   7,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd0bYFuZoaQ8",
        "colab_type": "code",
        "outputId": "79b2a5d3-d01f-414c-e05f-58eccacc8b46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "char2int['End']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FjJL1enZjie",
        "colab_type": "text"
      },
      "source": [
        "##Data analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLHhz4B4Z03w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flatten2D(grid):\n",
        "  a=[]\n",
        "  for x in grid:\n",
        "    a.extend(x)\n",
        "  return a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weR4AgCCZgf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from collections import Counter\n",
        "import operator\n",
        "def get_top10(aug_data):\n",
        "  flatten_aug_data=flatten2D(aug_data)\n",
        "  counter_levels=Counter(flatten_aug_data)\n",
        "  percent_levels=sorted([[i, (counter_levels[i] / len(flatten_aug_data) * 100.0)] for i in counter_levels],reverse=True,key=operator.itemgetter(1))\n",
        "  return percent_levels[1:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOiB_r_CbmLz",
        "colab_type": "code",
        "outputId": "d908488d-ea07-468d-ed08-0383d7a96fe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print(\"Top 10 Symptoms\")\n",
        "print(get_top10(real_data))\n",
        "print(\"Top 10 symptoms levels\")\n",
        "a=get_top10(aug_data)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 10 Symptoms\n",
            "[['R074', 1.533902411749357], ['F329', 1.2412867633354456], ['F103', 1.0008573452119134], ['R104', 0.926305587654229], ['R55', 0.892757296753271], ['F102', 0.8834383270585604], ['F100', 0.8815745331196183], ['T391', 0.8032951876840496], ['R073', 0.6989227271032915]]\n",
            "Top 10 symptoms levels\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKx8MyOKcROt",
        "colab_type": "code",
        "outputId": "9c3921d3-278d-4ce3-e2a7-7490ab8b7b06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "top10_levels=np.array(get_top10(aug_data))\n",
        "#top10_levels[:,1].astype(int)\n",
        "y_pos = np.arange(len(top10_levels[:,0]))\n",
        " \n",
        "# Create bars\n",
        "plt.bar(y_pos, top10_levels[:,1])\n",
        " \n",
        "# Create names on the x-axis\n",
        "plt.xticks(y_pos, top10_levels[:,0])\n",
        " \n",
        "# Show graphic\n",
        "plt.show()\n",
        "\n",
        "#plt.bar(top10_levels[:,0],top10_levels[:,1])\n",
        "top10_symptoms=np.array(get_top10(real_data))\n",
        "#plt.bar(top10_symptoms[:,0],top10_symptoms[:,1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdMAAAD4CAYAAAC34gzsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd7gdZbn+8e9NCh1BEhAIISD9UAJs\nQaQkhiKKghQhqBQbonBAsAAHDyrIJQhywB94EJWmNA3F0PFQBIQgCaSHToQAEmliQEqS+/fHvAvG\n5doFFjs7nnN/rmtde+aZt81s5dnvO7Mmsk1ERES8c4v09QAiIiL+1SWZRkREtCnJNCIiok1JphER\nEW1KMo2IiGhT/74eQPSNQYMGediwYX09jIiIfxkTJkx41vbgVseSTP+PGjZsGOPHj+/rYURE/MuQ\n9KfOjmWZNyIiok1JphEREW1KMo2IiGhTkmlERESbkkwjIiLalGQaERHRph4lU0mrSrpF0nRJ0yQd\n1qLMeyRdJWlSKfO52rEfltgMST+WpBIfKOlsSQ9Kul/SHiW+mqSbJE2WdKukIbX4vZImlvYOqvVx\ngqQnJM1pMba9amO/qLu2avXGSppa299Y0l2SppRzXaZ2HueW+CRJI2t19i7nMU3SSd2Nq3ZsGUmz\nJJ3Rk3Msx/eQZEkdrY5HREQvsd3tB1gJ2LRsLw08CKzfVOY/gJPK9mDgeWAg8CHgD0C/8rkLGFnK\nfQ/4ftleBBhUtn8D7F+2RwG/LNsDgUXL9lLATGDlsv/BMs45TeNaC7gPWK7sr9BdWyW2O3ARMLUW\nuwcYUbY/Dxxftg8Gzm20D0wo57M88DgwuBw7H9iuq3HV+jq99H9GLdbyHGu/l9uAcUBHd7/TzTbb\nzBER0XPAeHfy39QezUxtP2373rL9N2AGsEpzMWDpMutciiqZzi3xxRrJCxgAPFPqfB74QWl3vu1n\nS3x94OayfQuwaynzuu3XSnxRajNr2+NsP91i+F8CzrT9Qik3u7u2JC0FHAF8v6mttakSFsDvgD2a\nx1vafxHoANYAHrL9l1Luf2p1Wo6r9L8ZsCJwY73zLs4R4HjgJODVTo5HREQvedtvQJI0DNgEuLvp\n0BnAWOApqlnS3rbnA3dJugV4GhDVTGuGpGVLvePLsugjwCG2nwEmUc0MTwd2o0rSy9t+TtKqwDXA\nmsA3bT/VzZDXLuNuzI6/a/v6EuusreOBHwGvNLU1jSqxXwl8Cli1xCcBu0i6uMQ2Kz9vBtYp12wW\n8EmqPyo6HZekRUrfnwW27+bcKG1sCqxq+xpJ3+yi3IHAgQBDhw7tSdMREb1q2FHXLND+Zp64c6+0\n+7YeQCoztsuAr9l+qenwR4CJwMrAcOCMct9vTWA9YAjVbHaUpG2oEvkQ4E7bm1It/55S2voGMELS\nfcAI4ElgHoDtJ2xvRJUA95e0YjfD7k+1pDoS2Af4WSORt2pL0nDg/bavaNHW54GvSppA9QfD6yV+\nDlWyHA+cBtwJzCuzzq8AlwK3Uy0lz+tmXF8FrrU9q5vzAqAk31OBr3dX1vbZtjtsdwwe3PL1khER\n8Q70eGYqaQBVIr3Q9uUtinwOOLGsKz8s6TFgXapkOM72nNLOdcCWwB1UM79GW78BvgBQZoi7l/JL\nAXvYfrHeme2nysNB2wBjuhj6LOBu228Aj0l6kCqJ3dNJW4OBDkkzqa7PCpJutT3S9v3AjmVcawM7\nl/pzgcNr1+pOqvvK2L4KuKrED+StZNrZuLYEtpH0Varl8oGS5tg+qpPzWxrYALi1PNf1PmCspF1s\n5+W7ERELQE+f5hXwC2CG7VM7KfY4sF0pvyKwDvBoiY+Q1L8k5BGlHVMlmZGl/nbA9FJ/UJlxARxN\nNfND0hBJi5ft5YCtgQe6Gf6VjT4kDaJaXn20s7Zs/7ftlW0PK7EHbTfqr1B+LgJ8Gzir7C8hacmy\nvQMw1/b0pjrLUc06f97VuGx/xvbQ0v83gAu6SKTY/qvtQbaHlTrjgCTSiIgFqKfLvFsB+1It0U4s\nn49JOqj2lZLjgQ9JmgLcBBxZHigaQ3U/dArVvcVJZbYGcCTwXUmTS/uNpcqRwANltrYicEKJrwfc\nLWkS8HvgFNtT4M2v38wClihfKfluqXMD8Jyk6VQPM33T9nNdtdWFfcqY7qe6N3xuia8A3CtpRjmn\nfWt1Ti99/4Fq5v5gN+PqVBfnGBERfUjVBDH+r+no6HD+CbaI6Gv/Sg8gSZpgu+X3+PMGpIiIiDYl\nmUZERLQpyTQiIqJNSaYRERFtSjKNiIhoU5JpREREm5JMIyIi2pRkGhER0aYk04iIiDYlmUZERLQp\nyTQiIqJNSaYRERFtSjKNiIhoU5JpREREm5JMIyIi2pRkGhER0aYeJVNJq0q6RdJ0SdMkHdaizHsk\nXSVpUinzudqxH5bYDEk/VmVpSRNrn2clnVbKrybpJkmTJd0qaUgtfm8pP03SQbU+TpD0hKQ5TeM6\nSNKUUucOSeuX+A6SJpRjEySNqtUZKOlsSQ9Kul/SHiU+tFyH+8rYPlbiAySdX9qaIenoWls7SXpA\n0sOSjqrFf1Gu1WRJYyQtVeJHlOs8uVyD1Up8uKS7ynlPlrR3i9/Bj5vPPyIiel9PZ6Zzga/bXh/4\nIHBwIynVHAxMt70xMBL4UUlKHwK2AjYCNgA+AIyw/Tfbwxsf4E/A5aWtU4ALbG8EHAf8oMSfBrYs\n5bcAjpK0cjl2FbB5i7FfZHvDUueHwKkl/izwCdsbAvsDv6zVOQaYbXttYH3g9yX+beDXtjcBRgM/\nKfFPAYuWtjYDvixpmKR+wJnAR0s7+9Su2+G2Ny7n+DhwSInfB3SU+JgyZoBXgP1s/xuwE3CapGUb\nA5bUASzX4vwjIqKX9SiZ2n7a9r1l+2/ADGCV5mLA0pIELAU8T5WEDSwGDAQWBQYAz9QrSlobWAG4\nvYTWB24u27cAu5a+X7f9WokvWh+/7XG2n24x9pdqu0uW8WD7PttPlfg0YHFJi5b9z1MSuO35tp+t\nneMyZfs9wFO1+JKS+gOLA68DL1El94dtP2r7deCS2rm8VM5dpU5jXLfYfqW0Ow4YUuIP2n6obD8F\nzAYGlzb6AScD32o+/4iI6H1v+56ppGHAJsDdTYfOANajSjBTgMNKIrqLKiE+XT432J7RVHc0cKlt\nl/1JwO5lezeqJL186X9VSZOBJ4CTagmxqzEfLOkRqlneoS2K7AHca/u12mzv+LKk/BtJK5bYd4HP\nSpoFXAv8e4mPAV4u5/c4cIrt56n+4Hii1s8san+ESDoX+DOwLvD/WozrC8B1Lc5nc6o/Th4poUOA\nsa3+mIiIiN7X/+0ULvf1LgO+1jTjA/gIMBEYBbwf+J2k26lmnOtRZlglvo3t22t1RwP71va/AZwh\n6QDgNuBJYB6A7SeAjcry7pWSxtj+h5luM9tnAmdK+jTVUu3+tXP6N+AkYMcS6l/GeqftIyQdQbXs\nvC+wD3Ce7R9J2hL4paQNqGag84CVqZZab5f0P12NqYzrc2VW+f+AvYFza+P6LNABjKjXkbQS1ZL0\n/rbnl+vwKaql9S5JOhA4EGDo0KHdFY+I/8WGHXXNAu1v5ok7L9D+FrQez0wlDaBKpBfavrxFkc8B\nl7vyMPAY1YxrN2Cc7Tm251DNtLastbsx0N/2hEbM9lO2dy/3Jo8psRfrnZUZ6VRgm56eA9Uy6ydr\nfQ8BrqC6F9mY5T1HdX+ycY6/ATYt218Afl36v4tq+XoQ8Gngettv2J4N/IEqET4JrFrrf0iJ1c9j\nXhnXHrVxbV/Oe5fasjaSlgGuAY6xPa6ENwHWBB6WNBNYQtLDrU7e9tm2O2x3DB48uIvLFBERb0dP\nn+YV8Atghu1TOyn2OLBdKb8isA7waImPkNS/JOQRVPdcG/YBLm7qb5CkxtiOBs4p8SGSFi/bywFb\nAw90M/a1ars7Aw+V+LJUieko239oFChLzVfx1kxvO2B6i3NcjyqZ/qXER5X4klQPad0P3AOsJWl1\nSQOpZuBjVVmzlBewSymPpE2An1Il0tm18xhIlfgvsD2mNt5rbL/P9jDbw4BXbK/Z1TWJiIh3V0+X\nebeiWuacImliif0HMBTA9lnA8cB5kqYAAo60/aykMVSJZgrVQzbX276q1vZewMea+hsJ/ECSqZZ5\nDy7x9aieEnbp4xTbU6D6+g3VDHGJck/z57a/CxxSZnpvAC/w1hLvIVQzumMlHVtiO5YEdiTVEu5p\nVMmy8TWfrwM/k3R4OZcDbFvSmcC5kqaVcZ1re3IZ1yHADUA/4Bzb08ofCueXmaao7hF/pfRxMtUD\nXL+p8iyP296lXKdtgeXL8jel/8bvIyIi+ojeeuYn/i/p6Ojw+PHj+3oYEdFHFpZ7pgvLOHpC0gTb\nHa2O5Q1IERERbUoyjYiIaFOSaURERJuSTCMiItqUZBoREdGmJNOIiIg2JZlGRES0Kck0IiKiTUmm\nERERbUoyjYiIaFOSaURERJuSTCMiItqUZBoREdGmJNOIiIg2JZlGRES0Kck0IiKiTUmmERERbeqV\nZCppMUl/lDRJ0jRJ32tRZlFJl0p6WNLdkoaV+EBJ50qaUuqPrNXZrMQflvRjSWpq8+uSLGlQ2Vcp\n97CkyZI2bSq/jKRZks6oxQZKOlvSg5Lul7RHiR9U+p4o6Q5J65f4MEl/L/GJks6qtbV36XeapJNq\n8dUk3VSO3SppSO3YSZKmls/etbgknVDGNUPSoSW+nKQrSlt/lLTB2/x1RUREm3prZvoaMMr2xsBw\nYCdJH2wq8wXgBdtrAv8FNJLNlwBsbwjsAPxIUmOc/12Or1U+OzUak7QqsCPweK2Pj9bKHljq1x0P\n3NYUOwaYbXttYH3g9yV+ke0NbQ8HfgicWqvziO3h5XNQGc/ywMnAdrb/DXifpO1K+VOAC2xvBBwH\n/KDU2RnYtFyzLYBvSFqm1DkAWBVY1/Z6wCUl/h/AxNLWfsDpRETEAtUrydSVOWV3QPm4qdiuwPll\newywXZlprg/cXNqZDbwIdEhaCVjG9jjbBi4APllr77+AbzX1sytV0rLtccCypR0kbQasCNzYNK7P\nU5Kb7fm2ny3bL9XKLNnifJqtATxk+y9l/3+APcr2m+cI3FLG2YjfZnuu7ZeBybz1B8NXgONsz69d\nm39oy/b9wDBJK3YztoiIeBf1762GJfUDJgBrAmfavrupyCrAEwC250r6K7A8MAnYRdLFVDOxzcrP\n+cCsWv1ZpQ0k7Qo8aXtS08rvm33U60h6BvgR8Flg+9qYly2bx5fl5UeAQ2w/U44fDBwBDARG1dpd\nXdJ9wEvAt23fDjwMrFOWr2dRJf6BpfwkYHeqWeRuwNJlJjsJ+I6kHwFLAB8Gppc67wf2lrQb8Bfg\nUNsP1dq6XdLmwGrAEOCZpuuNpAOpZugMHTq0+XBE9LJhR12zQPubeeLOC7S//8t67QEk2/PKkugQ\nYPO3cS/vHKrkMx44DbgTmNdZYUlLUC11Hvs2hvdV4Frbs5ri/ct477S9KXAX1ZIsALbPtP1+4Ejg\n2yX8NDDU9iZUifYiScvYfoFqNnkpcDsws3Ye3wBGlAQ8AngSmGf7RuDacs4Xl/4bdRYFXrXdAfyM\n6joBnEg1454I/DtwH51cL9tn2+6w3TF48OAeX6yIiOhar81MG2y/KOkWquXKqbVDT1LNOGdJ6g+8\nB3iuLOEe3igk6U7gQeAFqkTXMKS08X5gdaAxKx0C3FtmaY0+mutsCWwj6avAUsBASXOAo4FXgMtL\n+d9Q3dttdgnl/qvt16juEWN7gqRHgLWB8bavAq4q53EgJcnZfopqNomkpYA9bL9Yjp0AnFCOXVTO\nHao/MBrjugI4t5R/CfhcKS/gMeDRFmOOiIhe0ltP8w5uLJlKWpzqQaL7m4qNBfYv23sCN9u2pCUk\nLVnq7gDMtT3d9tPAS5I+WJLGfsBvbU+xvYLtYbaHUSWdTW3/ufSxX3kS9oPAX20/bfsztoeW8t+g\nuq96VEnkVwEjy7i2oyyzSlqrNvadgYdq59qvbK9B9bDTo2V/hfJzOarZ8M/L/qDaQ1VHU2aZkvqV\n5V4kbQRsxFv3dK+kWvaFajb7YCm3rKTG8vEXqe651u/vRkREL+utmelKwPklySwC/Nr21ZKOo5qx\njQV+AfxS0sPA88DoUncF4AZJ86lmkfvW2v0qcB6wOHBd+XTlWuBjVPcvX6HM4LpxZBnXaVT3Jht1\nDpG0PfAG1Sy58YfAtsBxkt6guq97kO3ny7HTJW1cto+z3ZhljgR+IMlUTxMfXOIDqO59QnX/9bO2\n55ZjJwIXSjocmEOVOAHWo7rWBqbReiYdERG9qFeSqe3JwCYt4sfWtl8FPtWizExgnU7aHQ90ee+1\nzDYb2+atRNVZ+fOoEnRj/09UCbK53GGd1L8MuKyTY/t0Eh9D9QRzc/xVqqdzW9V5kWpG3By/i2pZ\nOSIi+kjegBQREdGmJNOIiIg2JZlGRES0Kck0IiKiTUmmERERbUoyjYiIaFOSaURERJuSTCMiItqU\nZBoREdGmJNOIiIg2JZlGRES0Kck0IiKiTUmmERERbUoyjYiIaFOSaURERJuSTCMiItqUZBoREdGm\nbpOppMUk/VHSJEnTJH2vRZkjJE2XNFnSTZJWqx2bJ2li+YytxW+vxZ+SdGWJv0fSVbX+PteDtn5R\nyk+WNEbSUiW+qKRLJT0s6W5Jw0p8B0kTJE0pP0fV2hoo6WxJD0q6X9Ie3bS1vKRbJM2RdEbTdbm+\ndh5nSepX4pfWzmOmpIm1OhtJuqvUmVKu/9K18hMlPSvptFL+AEl/qR37Yne/04iIeHf170GZ14BR\ntudIGgDcIek62+NqZe4DOmy/IukrwA+Bvcuxv9se3tyo7W0a25IuA35bdg8Gptv+hKTBwAOSLrT9\nemdtAYfbfqm0dSpwCHAi8AXgBdtrShoNnFTG9SzwCdtPSdoAuAFYpbR1DDDb9tqSFgHeW+KdtfUq\n8J/ABuVTt5ftlyQJGAN8CrjEduPaIOlHwF/Ldn/gV8C+tidJWh54w/arwPBanQnA5bV+LrV9SIvr\nEhERC0C3M1NX5pTdAeXjpjK32H6l7I4DhvR0AJKWAUYBVzaaA5YuCWgp4HlgbjdjbCRSAYvXxrcr\ncH7ZHgNsJ0m277P9VIlPAxaXtGjZ/zzwg9LufNvPdtPWy7bvoEqqLcdF9UfLQJquWxnvXsDFJbQj\nMNn2pFL/OdvzmuqsDawA3N7VNYmIiAWnJzNTyvLkBGBN4Ezbd3dR/AvAdbX9xSSNp0qIJ9q+sqn8\nJ4GbaonnDGAs8BSwNLC37fndtSXpXOBjwHTg6yW8CvAEgO25kv4KLE81M23YA7jX9muSli2x4yWN\nBB4BDrH9TA/b+ieSbgA2L9dkTNPhbYBnbD9U9tcGXOoMpprF/rCpzmiqmWg9Me8haVvgQapZ+hOd\njOVA4ECAoUOHdjXsiP9Vhh11zQLra+aJOy+wvmLh0aMHkGzPK8urQ4DNy9LoP5H0WaADOLkWXs12\nB/Bp4DRJ72+qtg9vzcwAPgJMBFamWto8o8xeu2zL9udKnRm8tcTcJUn/RrVc++US6l/O8U7bmwJ3\nAaf0pK3O2P4IsBKwKNUMvK753PsDWwOfKT93k7RdU53RTXWuAobZ3gj4HW/NnluN5WzbHbY7Bg8e\n/E5OJyIiWnhbT/PafhG4Bdip+Zik7anuN+5i+7VanSfLz0eBW4FNanUGUc3a6n82fg64vCwvPww8\nBqzbXVslPg+4hGq2CfAksGrpqz/wHuC5sj8EuALYz/YjpfxzwCu8dT/yN8Cm3bXVnXLP87dUS8WN\nc+8P7A5cWis6C7jN9rNl2fzaWv9I2hjob3tCre3natf758BmPRlTRES8e3ryNO/gxvKnpMWBHYD7\nm8psAvyUKpHOrsWXa9yLLIlzK6pl2IY9gatLsml4HNiu1FkRWAd4tLO2VFmzxAXsUhvfWGD/Wl83\n23Y5n2uAo2z/odFxWTq9ChhZQtvVxtuyrS6u21KSVirb/YGdm67b9sD9tmfVYjcAG0paotQZ0XS9\nmmeyNPoodqGamUdExALUk3umKwHnl/umiwC/tn21pOOA8bbHUi3rLgX8pspnPG57F2A94KeS5pe6\nJ9quJ4fRVE/d1h0PnCdpCiDgSNvPSvpQq7bKE7fnl6VgAZOAr5S2fgH8UtLDVA8yjS7xQ6ju/x4r\n6dgS27H8IXBkqXMa8BeqmXJXbSFpJrAMMFDSJ6keJHoOGFv+AFiEakZ/VtO5/0NitP1CeRr5HqqH\nla61XZ+170V1X7juUEm7UN1Hfh44gIiIWKC6Taa2J9O0nFrix9a2t++k7p3Ahl20PbJF7CmqZNSj\ntsrDSVt10v6rVF9HaY5/H/h+J3X+BGzb07bKsWGt4sAHOolj+4BO4r+i+npMq2NrtIgdDRzdWT8R\nEdH78gakiIiINiWZRkREtCnJNCIiok1JphEREW1KMo2IiGhTkmlERESbkkwjIiLalGQaERHRpiTT\niIiINiWZRkREtCnJNCIiok1JphEREW1KMo2IiGhTkmlERESbkkwjIiLalGQaERHRpiTTiIiINrWV\nTCUtJumPkiZJmibpe12U3UOSJXWU/YGSzpU0pdQfWSt7gqQnJM1pamNRSZdKeljS3ZKGlfjmkiaW\nzyRJu9XqnCNptqSpTW19qox5fmNMJT5M0t9r7Z1V4kvXYhMlPSvptHJsW0n3Sporac+mfn5Y+pkh\n6ceqLCHpGkn3l2MnNtXZS9L0cuyiEhsu6a4Smyxp71r58yQ9Vhvb8G5+dRER8S7q32b914BRtudI\nGgDcIek62+PqhSQtDRwG3F0LfwnA9oaSVgCuk/QB2/OBq4AzgIea+vsC8ILtNSWNBk4C9gamAh22\n50paCZgk6Srbc4HzSlsXNLU1Fdgd+GmL83rE9j8kJNt/A96MSZoAXF52HwcOAL7RdN4fArYCNiqh\nO4ARwB+BU2zfImkgcJOkj9q+TtJawNHAVrZfKNcG4BVgP9sPSVoZmCDpBtsvluPftD2mxblEREQv\na2tm6kpj9jigfNyi6PFUie/VWmx94ObSzmzgRaCj7I+z/XSLdnYFzi/bY4DtJMn2KyVxAixWH4Pt\n24DnW4x9hu0HenSiTSStDawA3F7amml7MjC/uZsynoHAolTX55ky3ltK3deBe4Ehpc6XgDNtv1CO\nzy4/H7T9UNl+CpgNDH4n44+IiHdXuzNTJPUDJgBrUiWBu5uObwqsavsaSd+sHZoE7CLpYmBVYLPy\n849ddLcK8ARAmYX+FVgeeFbSFsA5wGrAvrXk+k6sLuk+4CXg27Zvbzo+GrjUdqs/HN5k+y5JtwBP\nAwLOsD2jXkbSssAngNNLaO0S/wPQD/iu7eub6mxOlaAfqYVPkHQscBNwlO3Xmscj6UDgQIChQ4d2\nNfSItg076poF2t/ME3deoP1F1LX9AJLteWVJdAiwuaQNGsckLQKcCny9RdVzgFnAeOA04E5gXhvj\nuNv2vwEfAI6WtNg7bOppYKjtTYAjgIskLdNUZjRwcXcNSVoTWI/q2qwCjJK0Te14/9LOj20/WsL9\ngbWAkcA+wM9Kwm3UWQn4JfC5siQO1bLwulTn/l7gyFbjsX227Q7bHYMHZ1IbEfFuedee5i337m4B\ndqqFlwY2AG6VNBP4IDBWUoftubYPtz3c9q7AssCD3XTzJNXstZGI3gM81zSOGcCc0u87OY/XbD9X\ntidQzf7WbhyXtDHQvxzrzm7AONtzynL4dcCWteNnAw/ZPq0WmwWMtf2G7ceorslape9lgGuAY+r3\npW0/XZbcXwPOBTZ/2yceERHvWLtP8w5uzJokLQ7sANzfOG77r7YH2R5mexgwDtjF9vjyROuSpe4O\nwFzb07vpciywf9neE7jZtiWtXpIrklajmqXNbOOc+pXtNagS2aO1IvvQg1lp8TgwQlL/8oDWCGBG\nafv7VH8MfK2pzpVUs1IkDaJK5I+WB5WuAC5oftCozFaRJOCTVA9XRUTEAtLuzHQl4BZJk4F7gN/Z\nvlrScZJ26abuCsC9kmZQLUvu2zhQvk4yC1hC0ixJ3y2HfgEsL+lhqiXYo0p8a6oneCdSJZyv2n62\ntHUxcBewTmnrCyW+W+ljS+AaSTeUtrYFJpe2xgAH2a4/wLQXTclU0gdKW58CfippWjk0hmpmO4Xq\nHvEk21dJGgIcQ/UQ1r3l6yxfLHVuAJ6TNJ1qpv/NMlPeq4ztgBZfgblQ0pTSzyDg+91c+4iIeBe1\n9QBSeYJ1kxbxYzspP7K2PRNYp5Ny3wK+1SL+KlXCao7/kuo+Yqu29ukkfgVV4m2OXwZc1qpOOb5G\ni9g9vPU0bj0+D/hyi/gsqgeSWrVvqj8UjmiK/wr4VSd1RnU23oiI6H15A1JERESbkkwjIiLalGQa\nERHRpiTTiIiINiWZRkREtCnJNCIiok1JphEREW1KMo2IiGhTkmlERESbkkwjIiLalGQaERHRpiTT\niIiINiWZRkREtCnJNCIiok1JphEREW1KMo2IiGhTkmlERESbeiWZSlpM0h8lTZI0TdL3Oim3l6Tp\npcxFtfj1kl6UdHVTeUk6QdKDkmZIOrTEd5U0WdJESeMlbV2r88PS/gxJP5akEr9V0gOlzkRJK5T4\nQZKmlNgdktYv8c/Uyk6UNF/S8HJsn1Jnchn7oBI/vjauGyWtXBvXyBKfJun33V03SbfX+n5K0pVN\n1+YDkuZK2vOd/dYiIuKd6t9L7b4GjLI9R9IA4A5J19ke1yggaS3gaGAr2y80kllxMrAE8OWmdg8A\nVgXWtT2/VucmYKxtS9oI+DWwrqQPAVsBG5VydwAjgFvL/mdsj2/q4yLbZ5Ux7gKcCuxk+0LgwhLf\nELjS9kRJ/YHTgfVtPyvph8AhwHeBk23/Z6lzKHAscJCkZYGflHYfr51Hp9fN9ja1a3cZ8Nvafj/g\nJOBGIiJigeuVmakrc8rugPJxU7EvAWfafqHUmV2rfxPwtxZNfwU4zvb8eh3bc2w32l+y1peBxYCB\nwKJlHM90M/aXarv1tur2AS4p2yqfJcusdxngqW7a+jRwue3Hm86j2+smaRlgFFCfmf47cBkwm4iI\nWOB6a2bamC1NANakSpp3N2jYz9EAABebSURBVBVZu5T7A9AP+K7t67tp9v3A3pJ2A/4CHGr7odLO\nbsAPgBWAnQFs3yXpFuBpqoR3hu0ZtfbOlTSPKhF9v5GQJR0MHEGVhEe1GMfewK6ljzckfQWYArwM\nPAQcXLsOJwD7AX8FPlw79wGSbgWWBk63fUEPr9sngZsaiVrSKsBupe0PdHXxJB0IHAgwdOjQrorG\nv7BhR12zwPqaeeLOC6yviIVZrz2AZHue7eHAEGBzSRs0FekPrAWMpJrp/awsf3ZlUeBV2x3Az4Bz\nav1dYXtdqmRzPICkNYH1yhhWAUZJaiyXfsb2hsA25bNvra0zbb8fOBL4dn0AkrYAXrE9tewPoJox\nbwKsDEymWr5utHWM7VWplogPqZ37ZlRJ/yPAf0pau4fXbR/g4tr+acCRjdl6V2yfbbvDdsfgwYO7\nKx4RET3U60/z2n4RuAXYqenQLKr7nG/Yfgx4kCq5dmUWcHnZvoK37oXW+7sNWKM8BLQbMK4sA88B\nrgO2LOWeLD//BlwEbN6iv0uoknPdaP4xmQ0v7TxSZra/Bj7Uoq0LgT1q53GD7ZdtPwvcBmzcdB7/\ndN3KOW0O1KceHcAlkmYCewI/kdQ85oiI6EW99TTv4MYsU9LiwA7A/U3FrqSalTaSxNrAo900fSVv\nLZWOoErASFqz9pTuplQz2OeAx4ERkvqXGeQIYEbZbzxxOwD4ONCYadYT+s5Uy7aN81oE2Iu37pcC\nPAmsL6kx1dsBmNGirV1r1+C3wNZlHEsAW5RxdXfd9gSutv1qI2B7ddvDbA8DxgBftf0PT/pGRETv\n6q17pisB55f7f4sAv7Z9taTjgPG2xwI3ADtKmg7MA75p+zmovgYCrAssJWkW8AXbNwAnAhdKOhyY\nA3yx9LcHsJ+kN4C/A3uXJ3vHUN3znEL1IM/1tq+StCRwQ0mk/YD/oVo2BjhE0vbAG8ALwP6189oW\neML2m0nf9lPlKyy3lf7/RPXUMcCJktYB5pf4QaXODEnXUy0Jzwd+bntqeRL5n65brf/R5RpERMRC\npFeSqe3JVPcQm+PH1rZN9ZDPES3KbdMcK/EXKQ8XNcVPovpqSHN8Hv/89Rpsv0x1z7JVH4e1ipdj\ntwIfbBE/CzirRXyP5ljt2MlUXwGqx1pet9rxkZ0dK8cP6Op4RET0jrwBKSIiok1JphEREW1KMo2I\niGhTkmlERESbkkwjIiLalGQaERHRpiTTiIiINiWZRkREtCnJNCIiok1JphEREW1KMo2IiGhTkmlE\nRESbkkwjIiLalGQaERHRpiTTiIiINiWZRkREtCnJNCIiok1tJ1NJ/STdJ+nqFsf+S9LE8nlQ0osl\n/uFafKKkVyV9shy7UNIDkqZKOkfSgBL/Zq38VEnzJL23HNup1HlY0lG1/m+v1XlK0pUlPlLSX2vH\njq3VmSlpSomPb3FOX5dkSYO6GpekdZrO8SVJXyt1hksa1+hD0ua19keW+DRJv+9uXJJOlnS/pMmS\nrpC07Dv/bUZExDvR/11o4zBgBrBM8wHbhze2Jf07sEmJ3wIML/H3Ag8DN5aiFwKfLdsXAV8E/tv2\nycDJpc4ngMNtPy+pH3AmsAMwC7hH0ljb021vU+v/MuC3teHdbvvjnZzTh20/2xyUtCqwI/B47Rxb\njgt4vnaO/YAngStKtR8C37N9naSPlf2RJRH+BNjJ9uOSVujBuH4HHG17rqSTgKOBIzs5r4iI6AVt\nzUwlDQF2Bn7eg+L7ABe3iO8JXGf7FQDb17oA/ggM6aatzYGHbT9q+3XgEmDXpnEuA4wCruzBOLvy\nX8C3AHdyvLNz3A54xPafyr5564+P9wBPle1PA5fbfhzA9uzuBmT7Rttzy+44Wl+viIjoRe3OTE+j\nSi5Ld1VI0mrA6sDNLQ6PBk5tUWcAsC/VzLceXwLYCTikhFYBnqgVmQVs0dTcJ4GbbL9Ui20paRJV\nIvuG7WklbuBGSQZ+avvs0u+uwJO2J0lqdY7N42o+x3qS/Rpwg6RTqP6g+VCJrw0MkHQr1TU93fYF\nXY2ryeeBS1vEG2M8EDgQYOjQoZ0Vi3dg2FHXLND+Zp648wLtLyK69o6TqaSPA7NtT5A0spvio4Ex\ntuc1tbESsCFwQ4s6PwFus317U/wTwB/KUmpP7cM/zp7vBVazPacss14JrFWObW37ybLE+jtJ9wPj\ngf+gWuLtTMtxSRoI7EK1/NrwFarl4Msk7QX8Atie6vexGdVMdnHgLknjbD/Yaly2b6v1cwwwl2qZ\nvKWSgM8G6Ojo6Gx2HRERb1M7y7xbAbtImkm1tDpK0q86Kds8M2vYC7jC9hv1oKTvAIOBI3rQ1pPA\nqrX9ISXWaGsQ1VLwm1MH2y/ZnlO2r6WaDQ4q+0+Wn7Op7nFuDryfamY9qZzvEOBeSe/rwTl+FLjX\n9jO12P7A5WX7N6UPqGbVN9h+udwbvQ3YuItxNc7xAODjwGfK8nhERCxA7ziZ2j7a9hDbw6gSyc22\nP9tcTtK6wHLAXS2a+ad7jJK+CHwE2Mf2/KZj7wFG8I8PEt0DrCVp9TILHA2MrR3fE7ja9qu1dt6n\nslZbnqRdBHhO0pKSli7xJalmolNtT7G9gu1h5XxnAZva/nMX4+r0HKmWlkeU7VHAQ2X7t8DWkvqX\nZeMtgBmdjavs70S11L5L475zREQsWO/G07z/QNJxwHjbjYQ2GrikecYkaRjVjPL3/KOzgD9RLXFC\n9UDOceXYbsCNtl9uFC5PsR5CtVTcDzindv+z0f+JTX3sCXxF0lzg78Bo25a0InBF6bc/cJHt63tw\n2v80rnKOS1I9ZfzlpvJfAk6X1B94lXIf0/YMSdcDk4H5wM9tT5W0RhfjOgNYlGrpF2Cc7YN6MOaI\niHiXvCvJ1PatwK1l+9imY9/tpM5MqoeHmuOdjsn2ecB5LeLXAtd2Umdki9gZVEmoOf4oZVm1K2V2\n2pNxvQws3yJ+B9W90VZtv/lVm56My/aa3Y03IiJ6V96AFBER0aYk04iIiDYlmUZERLQpyTQiIqJN\nSaYRERFtSjKNiIhoU5JpREREm5JMIyIi2pRkGhER0aYk04iIiDYlmUZERLQpyTQiIqJNSaYRERFt\nSjKNiIhoU5JpREREm5JMIyIi2pRkGhER0aa2k6mkmZKmSJooaXwnZUaW49Mk/b4WP7zEpkq6WNJi\nJX6epMdKnYmShpf4upLukvSapG809bGTpAckPSzpqBZj+LGkObX91STdJGmypFslDakdu17Si5Ku\nbmrjwtLHVEnnSBpQ4ruWdiZKGi9p61qd/SU9VD77l9jStXObKOlZSaeVYwfVrucdktYv8QGSzi/H\nZkg6+u38DiIiovf0f5fa+bDtZ1sdkLQs8BNgJ9uPS1qhxFcBDgXWt/13Sb8GRgPnlarftD2mqbnn\nS51PNvXRDzgT2AGYBdwjaazt6eV4B7BcU1unABfYPl/SKOAHwL7l2MnAEsCXm+pcCHy2bF8EfBH4\nb+AmYKxtS9oI+DWwrqT3At8BOgADE8q4XgCG18Y/Abi80a7ts0p8F+BUYCfgU8CitjeUtAQwXdLF\ntmeWep3+DiIionctiGXeTwOX234cwPbs2rH+wOKS+lMlr6e6asj2bNv3AG80HdoceNj2o7ZfBy4B\ndoU3E+3JwLea6qwP3Fy2b2mUL/3cBPytRf/XugD+CAwp8TklBrAkVeIE+AjwO9vPlwT6O6rE+CZJ\nawMrALeXtl6qHa63ZWDJcq0WB14H6mUjIqKPvBszUwM3SjLwU9tnNx1fGxgg6VZgaeB02xfYflLS\nKcDjwN+BG23fWKt3gqRjqWZ9R9l+rYsxrAI8UdufBWxRtg+hmjU+LaleZxKwO3A6sBuwtKTlbT/X\n3QmX5d19gcNqsd2oZrcrADt3Ma5VmpobDVxaS8ZIOhg4AhgIjCrhMVQJ/2mqPzwOt/18Odbd76DR\n7oHAgQBDhw7t7jQXesOOumaB9jfzxJ27LxQR/ye9GzPTrW1vCnwUOFjStk3H+wObUSWYjwD/KWlt\nSctRJYfVgZWpZl2NJdSjgXWBDwDvBY58JwOTtDLV8uj/a3H4G8AISfcBI4AngXk9bPonwG22b28E\nbF9he12qJejj38YwRwMX1wO2z7T9fqrz/nYJb17GtzLVNfu6pDXKse5+B412z7bdYbtj8ODBb2OI\nERHRlbaTqe0ny8/ZwBVU/9GvmwXcYPvlck/vNmBjYHvgMdt/sf0G1T3DD5W2ni6rqa8B57Zos9mT\nwKq1/SEltgmwJvCwpJnAEpIeLn08ZXt325sAx5TYi92dr6TvAIOpZo6trsdtwBqSBnUxrkZbGwP9\nbU/opLtLeOv+8KeB622/Ua71H6juxfbkdxAREb2orWQqaUlJSze2gR2BqU3FfgtsLal/eXBmC2AG\n1fLuByUtoWr9dbsSR9JK5aeokklzm83uAdaStLqkgVSzvbG2r7H9PtvDbA8DXrG9Zml7kKTG+R8N\nnNOD8/0i1ex6H9vza/E1y1iRtCmwKPAccAOwo6Tlykx8xxJr2IemWamktWq7OwMPle3HKUu+5Vp/\nELi/h7+DiIjoRe3eM10RuKLkkf5UT6JeL+kgANtn2Z4h6XpgMjAf+LntqQCSxgD3AnOB+4DGvb4L\nJQ0GBEwEDirl3weMB5YB5kv6GtXTwC9JOoQqUfUDzrE9rZuxjwR+UO4z3gYc3Dgg6XaqZealJM0C\nvmD7BuAs4E/AXeWcL7d9HLAHsJ+kN6ju/+5d7oE+L+l4qmQPcFztPifAXsDHmsZ1iKTtqR6yegHY\nv8TPBM6VNK1cl3NtTy5Lvf/0O+jm3CMi4l3UVjK1/SjVkm1z/Kym/ZOpnqhtLvcdqq+ONMdHNcdK\n/M+UJ2hbHLsWuLab8S5V2x5D9VBPq3LbdBJveb1snwSc1Mmxc+hk1mt7jRaxwzopO4fq/m9zvOXv\nICIiFpy8ASkiIqJNSaYRERFtSjKNiIhoU5JpREREm5JMIyIi2pRkGhER0aYk04iIiDYlmUZERLQp\nyTQiIqJNSaYRERFtSjKNiIhoU5JpREREm5JMIyIi2pRkGhER0aYk04iIiDYlmUZERLQpyTQiIqJN\nPUqmkpaVNEbS/ZJmSNqy6fhykq6QNFnSHyVtUOKrSrpF0nRJ0yQdVqtzcmlvcqm7bIl/RtLE2me+\npOHl2K2SHqgdW6HEV5N0U2nrVklDav1cL+lFSVc3jVmSTpD0YDmnQ0t819LOREnjJW1dq/PDch4z\nJP24tLF003iflXRaKb+tpHslzZW0Z1P/J0maWj571+KjSp2pks6X1L92XSZLmiLpTkkb1+rMLPGJ\nksb35HcaERHvnp7OTE8Hrre9LrAxMKPp+H8AE21vBOxXygPMBb5ue33gg8DBktYvx34HbFDqPAgc\nDWD7QtvDbQ8H9gUesz2x1tdnGsdtzy6xU4ALSlvHAT+olT+5tNPsAGBVYF3b6wGXlPhNwMal/88D\nPweQ9CFgK2AjYAPgA8AI23+rjWc48Cfg8tLW46Wfi+odS9oZ2BQYDmwBfEPSMpIWAc4HRtveoLS1\nf6n2WOlvQ+B44Oym8/lwGUNHi3ONiIhe1G0ylfQeYFvgFwC2X7f9YlOx9YGby/H7gWGSVrT9tO17\nS/xvVEl4lbJ/o+25pf44YAj/bB/eSnJdebN/4BZg18YB2zcBf2tR5yvAcbbnl3Kzy885tl3KLAk0\ntg0sBgwEFgUGAM/UG5S0NrACcHtpa6btycD8FuO9zfZc2y8Dk4GdgOWB120/WMr9DtijtHWn7RdK\nvLPrFRERfaB/D8qsDvwFOLcsLU4ADitJoGESsDtwu6TNgdWo/mP/ZrKRNAzYBLi7RR+fBy5tEd+b\nWmIszpU0D7gM+H5JfI3+Twd2A5aWtLzt57o4r/cDe0varZzfobYfKmPdjWp2uwKwM4DtuyTdAjwN\nCDjDdvMMfTRwaS0Zd2YS8B1JPwKWAD4MTAeeBfpL6rA9HtiTavbc7AvAdbV9AzdKMvBT282zVsp5\nHQgcWHbnSHqgm3G+2wZRnWNfe0fj0Em9MJKFZywLyzjgX3wsC8s44H/9WPpiHKt1esR2lx+gg2q5\ndouyfzpwfFOZZYBzgYnAL4F7gOG140tRJeHdW7R/DHAFoKb4FsCUptgq5efSwI3AfmV/Zaql1fvK\n+GYBy9bqjQSubmprDtUSNJQ/BFqMbVvgf8r2msA15VyWAu4CtmkqPx3YrEU75wF7tjjviVSzzwuB\nr5X4llQz2z8C36daPq/X+zDVDH/5FtdlBapEvW13v9e++ADj+3oMC9M4FqaxLCzjyFgW7nEsTGNZ\nWMbR+PTknuksYJbtxoxyDNX9vjfZfsn251zdM9wPGAw8CiBpANUs8kLbl9frSToA+DjVfdDm2dxo\n4OKmfp4sP/9GdR9y87L/lO3dbW9ClaTwPy9FtzqvxniuoLoX+g9s3wasIWkQ1Yx3nKtl4DlUM8M3\nH8Qqs/b+tid002+j7RNc3ePcgWqm+2CJ32V7G9ubA7c14qWPjaju4e7q2qy7dl1ml3PZvCdjiIiI\nd0e3ydT2n4EnJK1TQttRzcDeVJ72HVh2v0h1P/AlSaK61zrD9qlNdXYCvgXsYvuVpmOLAHtRu18q\nqX9Jao0E/XFgatkfVOpA9SDTOd2eOVxJNcsDGEFJWpLWLONG0qZU90efo3qYaEQZx4BSp77Muw9N\nyb8zkvpJWr5sb0SVyG8s+40nlBcFjgTOKvtDqZL/vn7rniqSlpS0dGMb2LFxXSIiYgHp4XR6ODCe\n6kGZK4HlgIOAg8rxLamS0QNU/8FfrsS3prqfN5lqSXMi8LFy7GHgiVr8rFp/I6lmgfUxLEm1VDwZ\nmEa1nNuvHNsTeKiM4efAorV6t1PdE/071Wz0IyW+LNWy7RSqJduNS/zI0v7EEt+6xPsBP6VKoNOB\nU5vG9yjVk8H12AdKny9TJeRpJb5YaWM61cNE9SXxk0sfD1CWfkv858ALtes1vsTXoFranVTGfUxf\nL3d08b+jA/t6DAvTOBamsSws48hYFu5xLExjWVjG0fioDCoiIiLeobwBKSIiok1JphEREW1KMo1e\nJWleec3hVElXNV4b2YfjOayMZZqkr/XhOObUtj9WXmvZ+XfYem8c50iaLanPH1qr/W+l8RnWB2NY\nvtb/nyU9Wdsf2H0L7+pYLOlXtf3+kv6iplejLsDxHF7+fzNV0sWSFuujcXT6mtq+lGQave3vrr4C\ntAHwPHBwXw1E1Tujv0T11aGNgY9LWrOvxlPGtB3wY+Cjtv/UB0M4j+rtWwuDxv9WGp+ZC3oAtp/z\nW68GPQv4r9p4Xl/Aw3kZ2EDS4mV/B+DJBTwGACStAhwKdJT/L/ej+vpiX+jqNbV9Jsk0FqS7KK+T\n7CPrAXfbfsXVqyx/T/XCjj4haVvgZ8DHbT/SF2Nw9V3q5/ui7+iRaylvYeNtfP2ul/QHFi//+MYS\nwFN9MQh38ZravpRkGguEpH5U31Ee24fDmApsU5bylgA+RuvXNS4Ii1J9zeyTrt5nHdV/qBtLqlf0\n9WAWEpcAo8uS6ka0fh1rr3P1YphTqL5v/zTwV9s39sVY6rp5Te0ClWQavW1xSROBPwMrUr0+sU+4\nepfySVQvyLie6vu68/poOG8Ad1K9Zzkq9WXe3fp6MAsDV/9QxjCqWem1fTUOSctRvSd9darXty4p\n6bN9NZ4ypqWo3q73Ndsv9eVYIMk0et/fy/2n1ahem9hn90wBbP/C9ma2t6V6CcaD3dXpJfOp3vK1\nuaT/6KMxxL+GsVSzwr5c4t2e6p/D/IvtN6hezvOhvhpMV6+p7StJprFAuHpl5KHA18s9lz5Re13j\nUKr7pRd1XaP3lGuyM/AZSZmhRmfOAb5ne0ofjuFx4IOSliivW92Of/53rReIrl5T25eSTGOBsX0f\n1esg9+nDYVwmaTpwFXCwu/8HEXqV7eepnqb9tqRdFnT/ki6mejBsHUmzktQXPrZn2f5xH4/hbqp/\n5OReqlewLgK0/KceF4CtgH2BUbV77B/ro7G8Ka8TjIiIaFNmphEREW1KMo2IiGhTkmlERESbkkwj\nIiLalGQaERHRpiTTiIiINiWZRkREtOn/A+ye60SikH2FAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf2qKJbW0qPf",
        "colab_type": "text"
      },
      "source": [
        "Mapping each of the level codes in histories to nos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amANcWru0Jzu",
        "colab_type": "code",
        "outputId": "c5990ed4-e4f2-41b5-f3c4-b4ae9e7ba4b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "int_data=[]\n",
        "for history in data:\n",
        "  int_data.append(np.array([char2int[level_code] for level_code in history],dtype=np.int32))\n",
        "int_data=np.array(int_data)\n",
        "print ('{}\\n mapped to integers:\\n {}'.format(repr(data[0]), int_data[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['D', '25', '9', 'F', '06', '7', 'H', '26', '9', 'End']\n",
            " mapped to integers:\n",
            " [113  28  99 116   7  77 118  29  99 115]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MC4ZvBBxi-d",
        "colab_type": "text"
      },
      "source": [
        "Creating training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhn6W6DN9j3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_histories=len(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAg_YNaSpXVC",
        "colab_type": "text"
      },
      "source": [
        "BLinding it with no 420"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3YC_YKV2ec6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Find the max length of history\n",
        "max_history_len=0\n",
        "for history in int_data:\n",
        "  max_history_len=max(len(history),max_history_len)\n",
        "print(\"Longest history of a patient: \",max_history_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAzugJNWx5Nh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_blinding(history):\n",
        "  n=len(history)\n",
        "  history=list(map(lambda x:x/132,history))\n",
        "  y_history=history.copy()\n",
        "  req_len=95-n\n",
        "  res=[]\n",
        "  for it in range(2*n):\n",
        "    temp=history.copy()\n",
        "    \n",
        "    blind_indices = random.sample(range(0, n), round(n*0.3)) \n",
        "    for i in blind_indices:\n",
        "      temp[i]=1   \n",
        "    #Padding shoudl be done here. since, \n",
        "    \n",
        "    temp=np.append(temp,[(char2int['End'])/132]*req_len)\n",
        "    y_history=np.append(history.copy(),[(char2int['End'])/132]*req_len)\n",
        "    \n",
        "    res.append([temp,y_history])\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_EkW7D6pcYb",
        "colab_type": "text"
      },
      "source": [
        "This is complete blinding. But needs to be optimized as the RAM limits the operation. Cool no problem as of now!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJKdAdCdvbxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import combinations \n",
        "BLIND_PERCENT=0.2\n",
        "def get_blind_histories(history):\n",
        "  n=len(history)\n",
        "  y_history,res=history,[]\n",
        "  comb = combinations(list(range(0,n)), int(n*BLIND_PERCENT)) \n",
        "  print(comb)\n",
        "  for c in list(comb):\n",
        "      history=y_history \n",
        "      for index in list(c):\n",
        "        history[index]=420\n",
        "      res.append([history,y_history])\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDzyIkWctxIA",
        "colab_type": "code",
        "outputId": "0086f8e0-a281-4ca6-a2f7-eee680d12f7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "print(\"Blinding the integer codes of diseases with no. 420\")\n",
        "print(\"BLINDING PERCENT 30%.\\n \")\n",
        "\n",
        "aug_int_data=[]\n",
        "for history in int_data:\n",
        "  aug_int_data.extend(random_blinding(history))\n",
        "n_aug_histories=len(aug_int_data)\n",
        "aug_int_data=np.array(aug_int_data)\n",
        "\n",
        "print(\"Length of complete data points:\",len(aug_int_data)) # blinded data\n",
        "print(\"Example of a blinded data pointL: \",aug_int_data[0])"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Blinding the integer codes of diseases with no. 420\n",
            "BLINDING PERCENT 30%.\n",
            " \n",
            "Length of complete data points: 296976\n",
            "Example of a blinded data pointL:  [[1.         0.21212121 0.75       0.87878788 0.0530303  1.\n",
            "  1.         0.21969697 0.75       0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212]\n",
            " [0.85606061 0.21212121 0.75       0.87878788 0.0530303  0.58333333\n",
            "  0.89393939 0.21969697 0.75       0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212 0.87121212\n",
            "  0.87121212 0.87121212 0.87121212 0.87121212 0.87121212]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zFe34LRpUwn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ffd084e-c063-4915-875e-5e2967c76398"
      },
      "source": [
        "len(aug_int_data[3][1])"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meR_wLQBjfru",
        "colab_type": "text"
      },
      "source": [
        "##From Tensorflow doc - Creating dataset\n",
        "https://www.tensorflow.org/tutorials/load_data/text\n",
        "\n",
        "Pytorch GRU with attention maps\n",
        "https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#sphx-glr-intermediate-seq2seq-translation-tutorial-py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGY8TLh9qeHm",
        "colab_type": "text"
      },
      "source": [
        "##Pytorch code starts here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5z4AE7_qjBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class listDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,aug_int_data):\n",
        "    self.aug_int_data=aug_int_data\n",
        "     \n",
        "    self.data_transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485],[0.229]) # need to normalize . How to do this will find out!.\n",
        "    ]) # oh my god! I also need to pad the input! Cool. # shoudl I do it before? would be easy.\n",
        "    \n",
        "  def __getitem__(self,index):\n",
        "    \n",
        "    blind_input=(self.aug_int_data[index][0]) # Rememeber each data point is a numpy array. Indexing might be different\n",
        "    real_input=(self.aug_int_data[index][1]) #need to put the data variable. \n",
        "    return blind_input,real_input\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.aug_int_data)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYa22W8v4P4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=listDataset(aug_int_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxvqERkfMcso",
        "colab_type": "text"
      },
      "source": [
        "Splitting into training and validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS3f9DyuMb8i",
        "colab_type": "code",
        "outputId": "35a50256-75ee-49a2-da6f-464306826fd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"Splitting the dataloader into training and validation..\\n\")\n",
        "train_size=int(train_split*len(dataset))\n",
        "val_size=len(dataset)-train_size\n",
        "batch_size=1\n",
        "train_dataset, val_dataset=torch.utils.data.random_split(dataset,[train_size,val_size])\n",
        "train_dataloader=torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                             batch_size=batch_size,\n",
        "                                             shuffle=True)\n",
        "num_batches=len(train_dataloader)\n",
        "val_dataloader=torch.utils.data.DataLoader(dataset=val_dataset,\n",
        "                                             batch_size=batch_size,\n",
        "                                             shuffle=True)\n",
        "print(\"Length of train dataset :{}, of val dataset:{}\".format(\n",
        "    len(train_dataset),len(val_dataset)\n",
        "))"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Splitting the dataloader into training and validation..\n",
            "\n",
            "Length of train dataset :237580, of val dataset:59396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTP9FKAZNWVU",
        "colab_type": "text"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ26mkA3NV5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Autoencoder(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,latent_rep_size):\n",
        "    super(Autoencoder,self).__init__()\n",
        "    self.fc1= nn.Linear(input_size,hidden_size)\n",
        "    self.relu1=nn.ReLU()\n",
        "    self.fc2=nn.Linear(hidden_size,latent_rep_size)\n",
        "    self.relu2=nn.ReLU()\n",
        "    self.fc3=nn.Linear(latent_rep_size,hidden_size)\n",
        "    self.relu3=nn.ReLU()\n",
        "    self.fc4= nn.Linear(hidden_size,input_size)\n",
        "    self.t=nn.Tanh()\n",
        "    \n",
        "  def forward(self,x):\n",
        "    #print(x.shape)\n",
        "    out=self.fc1(x)\n",
        "    #out=self.relu1(out)\n",
        "    out=self.fc2(out)\n",
        "    #print(out.shape)\n",
        "    #out=self.relu2(out)\n",
        "    #print(out.shape)\n",
        "    out=self.fc3(out)\n",
        "    #out=self.relu3(out)\n",
        "    out=self.fc4(out)\n",
        "    return self.t(out).abs()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcV2QltYBdnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#parameters\n",
        "lr=0.02\n",
        "beta1=0.5\n",
        "beta2=0.999\n",
        "L1_lambda=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ogXHUq6OEcP",
        "colab_type": "code",
        "outputId": "39d04ea8-35d3-45f2-8813-10a8f54b08d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#device=\"cpu\"\n",
        "print(\"Training on device: \", device)\n",
        "input_size=95\n",
        "hidden_size=55\n",
        "latent_rep_size=15\n",
        "model=Autoencoder(input_size,hidden_size, latent_rep_size).to(device)\n",
        "print(model)\n",
        "\n",
        "#Loss and optimizer\n",
        "criterion=nn.MSELoss().to(device)\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=lr,betas=(beta1,beta2))"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on device:  cuda:0\n",
            "Autoencoder(\n",
            "  (fc1): Linear(in_features=95, out_features=55, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (fc2): Linear(in_features=55, out_features=15, bias=True)\n",
            "  (relu2): ReLU()\n",
            "  (fc3): Linear(in_features=15, out_features=55, bias=True)\n",
            "  (relu3): ReLU()\n",
            "  (fc4): Linear(in_features=55, out_features=95, bias=True)\n",
            "  (t): Tanh()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlZX_oIPX-W4",
        "colab_type": "code",
        "outputId": "70b790e9-693e-41e7-e0a0-bbd7d8121869",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "total_step=len(train_dataloader)\n",
        "#model.train()\n",
        "for epoch in range(num_epochs):\n",
        "  for i,(blind_vector,real_vector) in enumerate(train_dataloader):\n",
        "    blind_vector=blind_vector.to(device).float()\n",
        "    real_vector=real_vector.to(device).float() \n",
        "    \n",
        "    #forward pass\n",
        "    #print(real_vector)\n",
        "    outputs=model(blind_vector)\n",
        "    loss=criterion(outputs,real_vector)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if(i+1)%10000==0:\n",
        "      print('Epoch [{}/{}], Step[{}/{}],Loss:{:.4f}'\n",
        "           .format(epoch+1,num_epochs,i+1,total_step,loss.item()))"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step[10000/237580],Loss:0.3491\n",
            "Epoch [1/5], Step[20000/237580],Loss:0.0298\n",
            "Epoch [1/5], Step[30000/237580],Loss:0.3593\n",
            "Epoch [1/5], Step[40000/237580],Loss:0.0611\n",
            "Epoch [1/5], Step[50000/237580],Loss:0.0936\n",
            "Epoch [1/5], Step[60000/237580],Loss:0.1131\n",
            "Epoch [1/5], Step[70000/237580],Loss:0.1200\n",
            "Epoch [1/5], Step[80000/237580],Loss:0.0332\n",
            "Epoch [1/5], Step[90000/237580],Loss:0.1496\n",
            "Epoch [1/5], Step[100000/237580],Loss:0.0927\n",
            "Epoch [1/5], Step[110000/237580],Loss:0.0674\n",
            "Epoch [1/5], Step[120000/237580],Loss:0.2047\n",
            "Epoch [1/5], Step[130000/237580],Loss:0.0845\n",
            "Epoch [1/5], Step[140000/237580],Loss:0.0692\n",
            "Epoch [1/5], Step[150000/237580],Loss:0.0482\n",
            "Epoch [1/5], Step[160000/237580],Loss:0.2314\n",
            "Epoch [1/5], Step[170000/237580],Loss:0.1131\n",
            "Epoch [1/5], Step[180000/237580],Loss:0.0630\n",
            "Epoch [1/5], Step[190000/237580],Loss:0.2732\n",
            "Epoch [1/5], Step[200000/237580],Loss:0.2851\n",
            "Epoch [1/5], Step[210000/237580],Loss:0.2047\n",
            "Epoch [1/5], Step[220000/237580],Loss:0.1157\n",
            "Epoch [1/5], Step[230000/237580],Loss:0.1134\n",
            "Epoch [2/5], Step[10000/237580],Loss:0.1796\n",
            "Epoch [2/5], Step[20000/237580],Loss:0.3351\n",
            "Epoch [2/5], Step[30000/237580],Loss:0.0493\n",
            "Epoch [2/5], Step[40000/237580],Loss:0.1000\n",
            "Epoch [2/5], Step[50000/237580],Loss:0.2178\n",
            "Epoch [2/5], Step[60000/237580],Loss:0.1760\n",
            "Epoch [2/5], Step[70000/237580],Loss:0.3160\n",
            "Epoch [2/5], Step[80000/237580],Loss:0.3562\n",
            "Epoch [2/5], Step[90000/237580],Loss:0.0779\n",
            "Epoch [2/5], Step[100000/237580],Loss:0.1158\n",
            "Epoch [2/5], Step[110000/237580],Loss:0.1884\n",
            "Epoch [2/5], Step[120000/237580],Loss:0.0851\n",
            "Epoch [2/5], Step[130000/237580],Loss:0.0638\n",
            "Epoch [2/5], Step[140000/237580],Loss:0.1726\n",
            "Epoch [2/5], Step[150000/237580],Loss:0.1052\n",
            "Epoch [2/5], Step[160000/237580],Loss:0.1446\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-235-d11d68944b33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foG3w6LglRvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion(model(blind_vector),real_vector)\n",
        "pred=model(blind_vector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_eAa0Qlt5_l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae97078c-f8c1-4ddd-f002-9fd2bc2ce262"
      },
      "source": [
        "criterion(pred[0][92],real_vector[0][92])"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(12996., device='cuda:0', grad_fn=<MseLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmJ5I68Lw2VG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4395b5db-f28b-465c-aa6e-177f336ff81e"
      },
      "source": [
        "def decode_disease(vector):\n",
        "  "
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(115., device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyzFJc5fABJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "print(\"Avg one epoch ptime: %.2f, total %d epochs ptime: %.2f\" % (torch.mean(torch.FloatTensor(train_hist['per_epoch_ptimes'])), train_epoch, total_ptime))\n",
        "  \n",
        "torch.save(G.state_dict(), 'generator_param.pkl')\n",
        "torch.save(D.state_dict(), 'discriminator_param.pkl')\n",
        "with open('train_hist.pkl', 'wb') as f:\n",
        "    pickle.dump(train_hist, f)\n",
        "\n",
        "utils.show_train_hist(train_hist, save=True, path=\"/content/drive/My Drive/Lumentum/NAVA_ocr/\" + 'train_hist.png')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}