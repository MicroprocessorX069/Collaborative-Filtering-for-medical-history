{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DAE pytorch one hot_1",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MicroprocessorX069/Collaborative-Filtering-for-medical-history/blob/master/DAE_pytorch_one_hot_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXlc4A-xMObg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J88tQp2L-ktx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "from torch import nn, optim\n",
        "from torch.autograd.variable import Variable\n",
        "from torchvision import transforms, datasets\n",
        "import os\n",
        "from PIL import Image\n",
        "import glob\n",
        "import PIL\n",
        "from PIL import ImageFont\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from bokeh.io import curdoc, show, output_notebook\n",
        "from bokeh.layouts import column\n",
        "from bokeh.models import ColumnDataSource\n",
        "from bokeh.plotting import figure\n",
        "from functools import partial\n",
        "from threading import Thread\n",
        "from tornado import gen\n",
        "import time\n",
        "import pickle\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm\n",
        "#parameters\n",
        "batch_size=100\n",
        "train_split=0.8\n",
        "num_epochs=5\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdh__AoSYHCe",
        "colab_type": "text"
      },
      "source": [
        "#To copy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeKL-SIvvVf6",
        "colab_type": "code",
        "outputId": "2169f06b-4d2a-4a26-dc89-38f8d76fd5bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime\n",
        "import random"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvHkHgh5QtYA",
        "colab_type": "text"
      },
      "source": [
        "http://biobank.ctsu.ox.ac.uk/crystal/field.cgi?id=41202"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_1HnrK2O5eA",
        "colab_type": "code",
        "outputId": "ed115a7c-9856-4863-b3df-310a269bb7cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWf-SqtJPIrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#paths\n",
        "root_dir=\"/content/drive/My Drive/Projects/Collaborative filtering/\"\n",
        "fcodes_dataset_path=\"/content/drive/My Drive/Projects/Collaborative filtering/Datasets/fcodesbucket edited - fcodesbucket.csv\"\n",
        "version=\"dae-3\"\n",
        "ckpt_dir=\"/content/drive/My Drive/Projects/Collaborative filtering/Implementations/dae-3/checkpoints/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SFyeB66QHbV",
        "colab_type": "code",
        "outputId": "9eac541b-33f8-4fc8-c53b-3f37f8401dfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text=open(fcodes_dataset_path).read()\n",
        "print(\"Text is {} characters long\".format(len(text)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text is 381175 characters long\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5ak2el8j5q8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-LnL7wGj9eE",
        "colab_type": "code",
        "outputId": "7449dee1-618d-4f25-b26d-4571a6f545f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "histories=[h for h in text.split('\\n')]\n",
        "print(\"Data has {} patient histories\".format(len(histories)))\n",
        "n_patients=len(histories)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data has 6237 patient histories\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx4nx_oZkfiW",
        "colab_type": "code",
        "outputId": "6ada0012-2a24-4bca-9e75-3963910609da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_patients=len(histories)\n",
        "\n",
        "real_data=[]\n",
        "for history in histories:\n",
        "  real_data.append([symptom for symptom in history.split(',')])\n",
        "for history in real_data:\n",
        "  while \"\" in history:\n",
        "    history.remove(\"\")\n",
        "  history.append(\"End\")\n",
        "\n",
        "real_data[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['H269', 'D259', 'F067', 'End']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7RGQ2_Fmis_",
        "colab_type": "text"
      },
      "source": [
        "Sorting the symptoms, except the last 'end'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiB3IKvXmegm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i,_ in enumerate(real_data):\n",
        "  real_data[i]=sorted(real_data[i][:-1])+[real_data[i][-1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtwtPnTvsbs0",
        "colab_type": "text"
      },
      "source": [
        "Splitting each symptom in to 3 levels\n",
        "e.g. A423 as A, 42, 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTNKON-_3Cqv",
        "colab_type": "text"
      },
      "source": [
        "Splitting one history into multiple sub histories\n",
        "H, 20, 4, G,12,6 into\n",
        "[H],[H,20],[H,20,4],[H,20,4,G]\n",
        "\n",
        "Min length has to be 4.\n",
        "i.e. One whole symptom has to be there (Not split, whole with all 3 levels) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HCoNkH0qwS9",
        "colab_type": "code",
        "outputId": "142d7a3a-48b7-4f99-d539-9ac347ac9e92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data=[]\n",
        "for history in real_data:\n",
        "  hist=[]\n",
        "  for s in history:\n",
        "    if s!=\"End\":\n",
        "      try:\n",
        "        hist.extend([s[0],s[1:3],s[3]])\n",
        "      except:\n",
        "        hist.extend([s[0],s[1:3],'0'])\n",
        "    else:\n",
        "      hist.append(s)\n",
        "  data.append(hist)\n",
        "data[0]\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['D', '25', '9', 'F', '06', '7', 'H', '26', '9', 'End']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JOR_a-Ugrji",
        "colab_type": "code",
        "outputId": "40c82c17-da1f-4d7a-e8fd-a7c5f28eacd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['H', '26', '9', 'D', '25', '9', 'F', '06', '7', 'End']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT-x2NT5xb9E",
        "colab_type": "text"
      },
      "source": [
        "Combining all histories to one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L5Ox7NTxMHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=[]\n",
        "for history in data:\n",
        "  text.extend(history)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSfwTddbxsAW",
        "colab_type": "text"
      },
      "source": [
        "Each characted mapped as a no."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kpxehY7xbUL",
        "colab_type": "code",
        "outputId": "c6eb5bf2-6b5c-4c83-8bc0-adb26e91e3a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "vocab=sorted(set(text))\n",
        "print(\"There are {} unique characters\".format(len(vocab)))\n",
        "char2int={c:i for i,c in enumerate(vocab)}\n",
        "int2char=np.array(vocab)\n",
        "print(\"Vector:\\n\")\n",
        "for char,_ in zip(char2int,range(8)):\n",
        "  print(' {:4s}: {:3d},'.format(repr(char), char2int[char]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 132 unique characters\n",
            "Vector:\n",
            "\n",
            " '0' :   0,\n",
            " '00':   1,\n",
            " '01':   2,\n",
            " '02':   3,\n",
            " '03':   4,\n",
            " '04':   5,\n",
            " '05':   6,\n",
            " '06':   7,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd0bYFuZoaQ8",
        "colab_type": "code",
        "outputId": "79b2a5d3-d01f-414c-e05f-58eccacc8b46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "char2int['End']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FjJL1enZjie",
        "colab_type": "text"
      },
      "source": [
        "##Data analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLHhz4B4Z03w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flatten2D(grid):\n",
        "  a=[]\n",
        "  for x in grid:\n",
        "    a.extend(x)\n",
        "  return a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf2qKJbW0qPf",
        "colab_type": "text"
      },
      "source": [
        "Mapping each of the level codes in histories to nos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amANcWru0Jzu",
        "colab_type": "code",
        "outputId": "2ef9d924-c02e-4182-a78c-95f260792a32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "int_data=[]\n",
        "for history in data:\n",
        "  int_data.append(np.array([char2int[level_code] for level_code in history],dtype=np.int32))\n",
        "int_data=np.array(int_data)\n",
        "print ('{}\\n mapped to integers:\\n {}'.format(repr(data[0]), int_data[0]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['D', '25', '9', 'F', '06', '7', 'H', '26', '9', 'End']\n",
            " mapped to integers:\n",
            " [113  28  99 116   7  77 118  29  99 115]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MC4ZvBBxi-d",
        "colab_type": "text"
      },
      "source": [
        "Creating training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhn6W6DN9j3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_histories=len(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAg_YNaSpXVC",
        "colab_type": "text"
      },
      "source": [
        "BLinding it with no 420"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3YC_YKV2ec6",
        "colab_type": "code",
        "outputId": "681e6492-fa9f-4d79-d08b-158bc1e5ae90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Find the max length of history\n",
        "max_history_len=0\n",
        "for history in int_data:\n",
        "  max_history_len=max(len(history),max_history_len)\n",
        "print(\"Longest history of a patient: \",max_history_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longest history of a patient:  94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s5fnKdS9YHs",
        "colab_type": "code",
        "outputId": "ddfed6a4-5c11-4695-fdaa-fe3677a8bdcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Find the max length of history\n",
        "max_history_len=0\n",
        "for history in encode_data:\n",
        "  max_history_len=max(len(history),max_history_len)\n",
        "print(\"Longest history of a patient: \",max_history_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longest history of a patient:  12408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAzugJNWx5Nh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_blinding(history):\n",
        "  n=len(history)\n",
        "  history=list(map(lambda x:x/132,history))\n",
        "  y_history=history.copy()\n",
        "  req_len=95-n\n",
        "  res=[]\n",
        "  for it in range(2*n):\n",
        "    temp=history.copy()\n",
        "    blind_indices = random.sample(range(0, n), round(n*0.3)) \n",
        "    for i in blind_indices:\n",
        "      temp[i]=1   \n",
        "    #Padding shoudl be done here. since, \n",
        "    \n",
        "    temp=np.append(temp,[(char2int['End'])/132]*req_len)\n",
        "    y_history=np.append(history.copy(),[(char2int['End'])/132]*req_len)\n",
        "    \n",
        "    res.append([temp,y_history])\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_EkW7D6pcYb",
        "colab_type": "text"
      },
      "source": [
        "This is complete blinding. But needs to be optimized as the RAM limits the operation. Cool no problem as of now!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDzyIkWctxIA",
        "colab_type": "code",
        "outputId": "27748812-75d9-4851-cf2f-ee3d481a596f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "print(\"Blinding the integer codes of diseases with no. 420\")\n",
        "print(\"BLINDING PERCENT 30%.\\n \")\n",
        "\n",
        "aug_int_data=[]\n",
        "for history in int_data:\n",
        "  aug_int_data.extend(random_blinding(history))\n",
        "n_aug_histories=len(aug_int_data)\n",
        "#aug_int_data=np.array(aug_int_data)\n",
        "\n",
        "print(\"Length of complete data points:\",len(aug_int_data)) # blinded data\n",
        "print(\"Example of a blinded data pointL: \",aug_int_data[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Blinding the integer codes of diseases with no. 420\n",
            "BLINDING PERCENT 30%.\n",
            " \n",
            "Length of complete data points: 296976\n",
            "Example of a blinded data pointL:  [array([0.85606061, 1.        , 0.75      , 1.        , 0.0530303 ,\n",
            "       0.58333333, 0.89393939, 1.        , 0.75      , 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212]), array([0.85606061, 0.21212121, 0.75      , 0.87878788, 0.0530303 ,\n",
            "       0.58333333, 0.89393939, 0.21969697, 0.75      , 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212,\n",
            "       0.87121212, 0.87121212, 0.87121212, 0.87121212, 0.87121212])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMoGZoQu3rU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_single_vector(vector):\n",
        "  res_vector=[]\n",
        "  for value in vector:\n",
        "    encoded_value=[0]*132\n",
        "    if value!=132:\n",
        "      encoded_value[value]=1\n",
        "    res_vector.append(encoded_value)\n",
        "  return res_vector\n",
        "\n",
        "def one_hot_encode(int_data):\n",
        "  res=[]\n",
        "  padded_input=[0]*132\n",
        "  padded_input[char2int['End']]=1\n",
        "  for history in int_data:\n",
        "    n=len(history)\n",
        "    #y_history=history.copy()\n",
        "    req_len=95-n\n",
        "    res.append(encode_single_vector(history)+[padded_input]*req_len)\n",
        "  return res\n",
        "\n",
        "def random_blinding(history):\n",
        "  n=len(history)\n",
        "  #y_history=history.copy()\n",
        "  req_len=95-n\n",
        "  res=[]\n",
        "  for it in range(2*n):\n",
        "    temp=history.copy()\n",
        "    blind_indices = random.sample(range(0, n), round(n*0.3)) \n",
        "    for i in blind_indices:\n",
        "      temp[i]=[0]*132   \n",
        "    #Padding shoudl be done here. since, \n",
        "    padded_input=[0]*132\n",
        "    padded_input[char2int['End']]=1\n",
        "    #temp=np.append(temp,[padded_input]*req_len)\n",
        "    #y_history=np.append(history.copy(),[padded_input]*req_len)\n",
        "    \n",
        "    res.append([np.append(temp,[padded_input]*req_len),np.append(history.copy(),[padded_input]*req_len)])\n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YdF7awl8vms",
        "colab_type": "code",
        "outputId": "43f3a828-f4d6-4408-df89-251b17d6abce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encode_data=one_hot_encode(int_data)\n",
        "print(\"Dimensions of encoded data are: ({},{},{})\".format(len(encode_data),len(encode_data[0]),len(encode_data[0][0])))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimensions of encoded data are: (6237,95,132)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6geTVpnB9Axs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"Blinding the integer codes of diseases with zeros\")\n",
        "# print(\"BLINDING PERCENT 30%.\\n \")\n",
        "\n",
        "# aug_encode_data=[]\n",
        "# for history in encode_data:\n",
        "#   aug_encode_data.extend(random_blinding(history))\n",
        "# n_aug_histories=len(aug_encode_data)\n",
        "# #aug_int_data=np.array(aug_int_data)\n",
        "\n",
        "# print(\"Length of complete data points:\",len(aug_encode_data)) # blinded data\n",
        "# print(\"Example of a blinded data pointL: \",aug_encode_data[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgBCUsppbPO2",
        "colab_type": "text"
      },
      "source": [
        "TODO: https://discuss.pytorch.org/t/where-is-the-noise-layer-in-pytorch/2887/6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meR_wLQBjfru",
        "colab_type": "text"
      },
      "source": [
        "##From Tensorflow doc - Creating dataset\n",
        "https://www.tensorflow.org/tutorials/load_data/text\n",
        "\n",
        "Pytorch GRU with attention maps\n",
        "https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#sphx-glr-intermediate-seq2seq-translation-tutorial-py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGY8TLh9qeHm",
        "colab_type": "text"
      },
      "source": [
        "##Pytorch code starts here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5z4AE7_qjBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class listDataset(torch.utils.data.Dataset):\n",
        "#   def __init__(self,aug_int_data):\n",
        "#     self.aug_int_data=aug_int_data\n",
        "     \n",
        "#     self.data_transform=transforms.Compose([\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Normalize([0.485],[0.229]) # need to normalize . How to do this will find out!.\n",
        "#     ]) # oh my god! I also need to pad the input! Cool. # shoudl I do it before? would be easy.\n",
        "    \n",
        "#   def __getitem__(self,index):\n",
        "    \n",
        "#     blind_input=(self.aug_int_data[index][0]) # Rememeber each data point is a numpy array. Indexing might be different\n",
        "#     real_input=(self.aug_int_data[index][1]) #need to put the data variable. \n",
        "#     return blind_input,real_input\n",
        "  \n",
        "#   def __len__(self):\n",
        "#     return len(self.aug_int_data)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ_xryc6Ku6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def single_random_blind(history):\n",
        "  n=len(history)\n",
        "  blind_indices = random.sample(range(0, n), round(n*0.3)) \n",
        "  for i in blind_indices:\n",
        "    history[i]=[0]*132\n",
        "  return history   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfFmyTSbKRw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class listDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,encode_data):\n",
        "    self.encode_data=encode_data\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    temp1,temp2=self.encode_data[index].copy(),self.encode_data[index].copy()\n",
        "    blind_input=flatten2D(single_random_blind(temp1)) \n",
        "    real_input=flatten2D(temp2) \n",
        "    return blind_input,real_input\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.encode_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7iRYdPmK_kS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=listDataset(encode_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYa22W8v4P4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset=listDataset(aug_int_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1ScUSjyLCU5",
        "colab_type": "code",
        "outputId": "0a4d9c00-67f6-4d20-e18e-3fa1e992018a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#example of an iteration of dataloader\n",
        "len(iter(torch.utils.data.DataLoader(dataset)).next()[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12540"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxvqERkfMcso",
        "colab_type": "text"
      },
      "source": [
        "Splitting into training and validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS3f9DyuMb8i",
        "colab_type": "code",
        "outputId": "1167ca93-5e67-4230-a08b-9646bbd28bf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"Splitting the dataloader into training and validation..\\n\")\n",
        "train_size=int(train_split*len(dataset))\n",
        "val_size=len(dataset)-train_size\n",
        "batch_size=64\n",
        "train_dataset, val_dataset=torch.utils.data.random_split(dataset,[train_size,val_size])\n",
        "train_dataloader=torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                             batch_size=1,\n",
        "                                             shuffle=True)\n",
        "num_batches=len(train_dataloader)\n",
        "val_dataloader=torch.utils.data.DataLoader(dataset=val_dataset,\n",
        "                                             batch_size=batch_size,\n",
        "                                             shuffle=True)\n",
        "print(\"Length of train dataset :{}, of val dataset:{}\".format(\n",
        "    len(train_dataset),len(val_dataset)\n",
        "))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Splitting the dataloader into training and validation..\n",
            "\n",
            "Length of train dataset :4989, of val dataset:1248\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A32J1BzLfZbv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f0d3fe0-9112-42db-f9e2-44fb44059f33"
      },
      "source": [
        "len(iter(train_dataloader).next()[0])\n",
        "#this means there are 2 lists, blind and real of 12540 tensors. and each tensor is of batch_size. BOOM\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj4hxz4hhpSc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33cc88b0-106d-43ef-e396-fe3c48a2697e"
      },
      "source": [
        "sum(train_dataset[1][1])"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTP9FKAZNWVU",
        "colab_type": "text"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ26mkA3NV5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Autoencoder(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,latent_rep_size):\n",
        "    super(Autoencoder,self).__init__()\n",
        "    self.fc1= nn.Linear(input_size,hidden_size)\n",
        "    self.relu1=nn.ReLU()\n",
        "    self.fc2=nn.Linear(hidden_size,latent_rep_size)\n",
        "    self.relu2=nn.ReLU()\n",
        "    self.fc3=nn.Linear(latent_rep_size,hidden_size)\n",
        "    self.relu3=nn.ReLU()\n",
        "    self.fc4= nn.Linear(hidden_size,input_size)\n",
        "    self.t=nn.Sigmoid()\n",
        "\n",
        "  def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m]) \n",
        "\n",
        "  def forward(self,x):\n",
        "    #print(x.shape)\n",
        "    out=self.fc1(x)\n",
        "    #out=self.relu1(out)\n",
        "    out=self.fc2(out)\n",
        "    #print(out.shape)\n",
        "    #out=self.relu2(out)\n",
        "    #print(out.shape)\n",
        "    out=self.fc3(out)\n",
        "    #out=self.relu3(out)\n",
        "    out=self.fc4(out)\n",
        "    return self.t(out)\n",
        "\n",
        "\n",
        "def normal_init(m, mean=0.0, std=0.02):\n",
        "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "        m.weight.data.normal_(mean, std)\n",
        "        m.bias.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcV2QltYBdnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#parameters\n",
        "lr=0.02\n",
        "beta1=0.5\n",
        "beta2=0.999\n",
        "L1_lambda=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ogXHUq6OEcP",
        "colab_type": "code",
        "outputId": "0f961397-fbef-4930-a427-c814196170ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#device=\"cpu\"\n",
        "print(\"Training on device: \", device)\n",
        "input_size=95\n",
        "hidden_size=55\n",
        "latent_rep_size=15\n",
        "model=Autoencoder(input_size,hidden_size, latent_rep_size).to(device)\n",
        "print(model)\n",
        "\n",
        "#Loss and optimizer\n",
        "criterion=nn.MSELoss().to(device)\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=lr,betas=(beta1,beta2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on device:  cuda:0\n",
            "Autoencoder(\n",
            "  (fc1): Linear(in_features=95, out_features=55, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (fc2): Linear(in_features=55, out_features=15, bias=True)\n",
            "  (relu2): ReLU()\n",
            "  (fc3): Linear(in_features=15, out_features=55, bias=True)\n",
            "  (relu3): ReLU()\n",
            "  (fc4): Linear(in_features=55, out_features=95, bias=True)\n",
            "  (t): ReLU()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlZX_oIPX-W4",
        "colab_type": "code",
        "outputId": "31321704-db86-4638-fff8-00e06005bce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        }
      },
      "source": [
        "total_step=len(train_dataloader)\n",
        "#model.train()\n",
        "for epoch in range(num_epochs):\n",
        "  for i,(blind_vector,real_vector) in enumerate(train_dataloader):\n",
        "    blind_vector=blind_vector.to(device).float()\n",
        "    real_vector=real_vector.to(device).float() \n",
        "    \n",
        "    #forward pass\n",
        "    #print(real_vector)\n",
        "    outputs=model(blind_vector)\n",
        "    loss=criterion(outputs,real_vector)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if(i+1)%10000==0:\n",
        "      print('Epoch [{}/{}], Step[{}/{}],Loss:{:.4f}'\n",
        "           .format(epoch+1,num_epochs,i+1,total_step,loss.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step[10000/237580],Loss:0.6572\n",
            "Epoch [1/5], Step[20000/237580],Loss:0.6332\n",
            "Epoch [1/5], Step[30000/237580],Loss:0.4702\n",
            "Epoch [1/5], Step[40000/237580],Loss:0.7148\n",
            "Epoch [1/5], Step[50000/237580],Loss:0.7339\n",
            "Epoch [1/5], Step[60000/237580],Loss:0.5839\n",
            "Epoch [1/5], Step[70000/237580],Loss:0.7049\n",
            "Epoch [1/5], Step[80000/237580],Loss:0.7209\n",
            "Epoch [1/5], Step[90000/237580],Loss:0.5961\n",
            "Epoch [1/5], Step[100000/237580],Loss:0.7339\n",
            "Epoch [1/5], Step[110000/237580],Loss:0.6289\n",
            "Epoch [1/5], Step[120000/237580],Loss:0.6840\n",
            "Epoch [1/5], Step[130000/237580],Loss:0.6992\n",
            "Epoch [1/5], Step[140000/237580],Loss:0.6808\n",
            "Epoch [1/5], Step[150000/237580],Loss:0.4390\n",
            "Epoch [1/5], Step[160000/237580],Loss:0.7112\n",
            "Epoch [1/5], Step[170000/237580],Loss:0.7008\n",
            "Epoch [1/5], Step[180000/237580],Loss:0.4849\n",
            "Epoch [1/5], Step[190000/237580],Loss:0.4139\n",
            "Epoch [1/5], Step[200000/237580],Loss:0.6688\n",
            "Epoch [1/5], Step[210000/237580],Loss:0.4125\n",
            "Epoch [1/5], Step[220000/237580],Loss:0.6895\n",
            "Epoch [1/5], Step[230000/237580],Loss:0.6166\n",
            "Epoch [2/5], Step[10000/237580],Loss:0.4947\n",
            "Epoch [2/5], Step[20000/237580],Loss:0.6802\n",
            "Epoch [2/5], Step[30000/237580],Loss:0.4374\n",
            "Epoch [2/5], Step[40000/237580],Loss:0.7210\n",
            "Epoch [2/5], Step[50000/237580],Loss:0.6630\n",
            "Epoch [2/5], Step[60000/237580],Loss:0.5646\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-251-d11d68944b33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#model.train()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblind_vector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreal_vector\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mblind_vector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblind_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mreal_vector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreal_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_fields'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# namedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msubtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             if (cls._abc_negative_cache_version ==\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0mABCMeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_abc_invalidation_counter\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m                 subclass in cls._abc_negative_cache):\n\u001b[1;32m    191\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUF7iWpH-pcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(),'model.ckpt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foG3w6LglRvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion(model(blind_vector),real_vector)\n",
        "pred=model(blind_vector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_eAa0Qlt5_l",
        "colab_type": "code",
        "outputId": "ae97078c-f8c1-4ddd-f002-9fd2bc2ce262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "criterion(pred[0][92],real_vector[0][92])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(12996., device='cuda:0', grad_fn=<MseLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmJ5I68Lw2VG",
        "colab_type": "code",
        "outputId": "0af817b9-228e-4a1b-8f8c-80cccab049ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def decode_disease(vector):\n",
        "  history=list(map(lambda x:x*132,vector))\n",
        "  for i,level in enumerate(history):\n",
        "    history[i]=int2char[int(level)] if int(level)<132 else 'Uk'\n",
        "  return history\n",
        "#print(real_vector)\n",
        "decode_disease(model(blind_vector)[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0',\n",
              " '0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs6WJM6F3fTz",
        "colab_type": "code",
        "outputId": "fb422f7e-c2c4-4455-b599-f1ad348339a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model(blind_vector)[0].detach()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnY7ELXn3jxo",
        "colab_type": "code",
        "outputId": "98f1a745-67b9-4fb0-a737-6ff8834dbea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "blind_vector"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8561, 0.2955, 0.0000, 0.8788, 0.4015, 0.0000, 0.9167, 0.3636, 0.0000,\n",
              "         0.9167, 0.3636, 1.0000, 0.9167, 1.0000, 0.2500, 0.9167, 1.0000, 0.0833,\n",
              "         0.9167, 1.0000, 0.1667, 1.0000, 0.1742, 0.0833, 1.0000, 1.0000, 0.2500,\n",
              "         0.9621, 0.0909, 0.2500, 0.9621, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000,\n",
              "         0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712,\n",
              "         0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712,\n",
              "         0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712,\n",
              "         0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712,\n",
              "         0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712,\n",
              "         0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712, 0.8712,\n",
              "         0.8712, 0.8712, 0.8712, 0.8712, 0.8712]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyzFJc5fABJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "print(\"Avg one epoch ptime: %.2f, total %d epochs ptime: %.2f\" % (torch.mean(torch.FloatTensor(train_hist['per_epoch_ptimes'])), train_epoch, total_ptime))\n",
        "  \n",
        "torch.save(G.state_dict(), 'generator_param.pkl')\n",
        "torch.save(D.state_dict(), 'discriminator_param.pkl')\n",
        "with open('train_hist.pkl', 'wb') as f:\n",
        "    pickle.dump(train_hist, f)\n",
        "\n",
        "utils.show_train_hist(train_hist, save=True, path=\"/content/drive/My Drive/Lumentum/NAVA_ocr/\" + 'train_hist.png')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}